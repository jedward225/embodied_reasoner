# Embodied-Reasonerå¯¼èˆªå¢å¼ºæ–¹æ¡ˆï¼šå®æ–½æŒ‡å—

## é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®æ—¨åœ¨è§£å†³Embodied-Reasonerä¸­çš„ä¸¤ä¸ªæ ¸å¿ƒå¯¼èˆªé—®é¢˜ï¼Œæä¾›ä¸€ä¸ªæ¸è¿›å¼ã€æ¨¡å—åŒ–çš„å®æ–½æ–¹æ¡ˆã€‚

## ğŸ’¡ ç¬¬ä¸€ä¸ªä»»åŠ¡å®æ–½æŒ‡å—

### ğŸ¯ ç›®æ ‡
å®Œæˆ**åŒåç‰©ä½“æ™ºèƒ½æ¶ˆæ­§**çš„åŸºç¡€å®ç°ï¼Œè®©ç³»ç»Ÿèƒ½å¤Ÿç†è§£"å·¦è¾¹çš„ä¹¦"ç­‰ç©ºé—´æè¿°ã€‚

### ğŸ“‹ å…·ä½“å®æ–½æ­¥éª¤

#### 1ï¸âƒ£ ç¯å¢ƒå‡†å¤‡
```bash
# ç¡®ä¿ç¯å¢ƒæ¿€æ´»
conda activate er_eval

# éªŒè¯spatial_enhancementæ¨¡å—æ­£å¸¸å·¥ä½œ
python test_spatial_enhancement.py
```

#### 2ï¸âƒ£ æ ¸å¿ƒæ¨¡å—ç†è§£
- **`spatial_calculator.py`**: è®¡ç®—ç‰©ä½“é—´çš„ç©ºé—´å…³ç³»ï¼ˆå‰åå·¦å³ã€è¿œè¿‘å…³ç³»ï¼‰
- **`heuristic_detector.py`**: æ£€æµ‹æ­§ä¹‰å¹¶ä½¿ç”¨å¯å‘å¼è§„åˆ™è§£å†³
- **`enhanced_agent.py`**: å¢å¼ºçš„RocAgentï¼Œæ•´åˆæ‰€æœ‰ç©ºé—´æ¨ç†åŠŸèƒ½

#### 3ï¸âƒ£ æµ‹è¯•å¢å¼ºåŠŸèƒ½
```bash
# è¿è¡Œå¢å¼ºç‰ˆè¯„ä¼°
python evaluate/evaluate_enhanced.py --input_path ./data/test_809.json --model_name test_enhanced

# å¯¹æ¯”åŸºç¡€ç‰ˆæœ¬
python evaluate/evaluate.py --input_path ./data/test_809.json --model_name test_baseline
```

#### 4ï¸âƒ£ æ€§èƒ½éªŒè¯
```bash
# ä½¿ç”¨æ€§èƒ½æ¯”è¾ƒå·¥å…·
python performance_comparison.py --data_file ./data/test_809.json --model_name Qwen2.5-VL-3B-Instruct
```

#### 5ï¸âƒ£ å…³é”®éªŒè¯ç‚¹
- âœ… å¤šä¸ªåŒç±»ç‰©ä½“åœºæ™¯ä¸­èƒ½æ­£ç¡®é€‰æ‹©ç›®æ ‡
- âœ… ç©ºé—´å…³ç³»è¯ï¼ˆå·¦å³å‰åï¼‰è§£ææ­£ç¡®
- âœ… åœ¨æ— æ³•ç¡®å®šæ—¶èƒ½ç”Ÿæˆæ¾„æ¸…é—®é¢˜
- âœ… å¤±è´¥æ—¶èƒ½ä¼˜é›…é™çº§åˆ°åŸå§‹æ–¹æ³•

#### 6ï¸âƒ£ æœŸæœ›æ”¹è¿›æŒ‡æ ‡
- **æˆåŠŸç‡æå‡**: 5-15%ï¼ˆç‰¹åˆ«æ˜¯å¤šç‰©ä½“åœºæ™¯ï¼‰
- **å¯¼èˆªç²¾åº¦**: 10-20%æå‡
- **ç”¨æˆ·ä½“éªŒ**: å‡å°‘å¤šè½®äº¤äº’éœ€æ±‚

### æ ¸å¿ƒé—®é¢˜

#### é—®é¢˜1ï¼šåŒåç‰©ä½“æ­§ä¹‰
**ç°çŠ¶ï¼š** å½“åœºæ™¯ä¸­å­˜åœ¨å¤šä¸ªåŒç±»å‹ç‰©ä½“æ—¶ï¼ˆå¦‚å¤šä¸ªä¹¦æ¶ï¼‰ï¼Œç³»ç»Ÿç®€å•é€‰æ‹©ç¬¬ä¸€ä¸ªï¼Œæ— æ³•ç†è§£"å·¦è¾¹çš„ä¹¦æ¶"è¿™ç±»è‡ªç„¶è¯­è¨€æŒ‡ä»¤ã€‚

**å½±å“ï¼š** 
- ä»»åŠ¡å¤±è´¥ç‡é«˜
- ç”¨æˆ·ä½“éªŒå·®
- éœ€è¦å¤šè½®äº¤äº’æ¾„æ¸…

#### é—®é¢˜2ï¼šå¤§å‹ç‰©ä½“è§‚å¯Ÿç­–ç•¥
**ç°çŠ¶ï¼š** ä½¿ç”¨å›ºå®šè·ç¦»é˜ˆå€¼ï¼Œå¯¹Lå‹æ²™å‘ç­‰å¤§å‹å¤æ‚ç‰©ä½“è§‚å¯Ÿä¸å……åˆ†ã€‚

**å½±å“ï¼š**
- è§‚å¯Ÿè¦†ç›–ç‡ä¸è¶³
- åç»­æ“ä½œå®šä½ä¸å‡†ç¡®
- ä»»åŠ¡å®Œæˆæ•ˆç‡ä½

## è§£å†³æ–¹æ¡ˆæ¶æ„

### æ•´ä½“è®¾è®¡åŸåˆ™
1. **é›¶è®­ç»ƒè¦æ±‚** - åˆ©ç”¨ç°æœ‰æ¨¡å‹èƒ½åŠ›ï¼Œæ— éœ€é¢å¤–è®­ç»ƒ
2. **æ¨¡å—åŒ–è®¾è®¡** - å„ç»„ä»¶ç‹¬ç«‹ï¼Œä¾¿äºæµ‹è¯•å’Œç»´æŠ¤
3. **å‘åå…¼å®¹** - ä¸ç ´åç°æœ‰åŠŸèƒ½ï¼Œå¯é€‰æ‹©æ€§å¯ç”¨
4. **æ€§èƒ½ä¼˜å…ˆ** - æœ€å°åŒ–è®¡ç®—å¼€é”€ï¼Œæ”¯æŒå®æ—¶å“åº”

### æŠ€æœ¯æ–¹æ¡ˆæ¦‚è§ˆ

```
å¯¼èˆªå¢å¼ºç³»ç»Ÿ
â”œâ”€â”€ ç©ºé—´æ„ŸçŸ¥æ¨¡å—
â”‚   â”œâ”€â”€ ç©ºé—´å…³ç³»è®¡ç®—å™¨
â”‚   â”œâ”€â”€ è‡ªç„¶è¯­è¨€è§£æå™¨
â”‚   â””â”€â”€ æ¶ˆæ­§å†³ç­–å¼•æ“
â”œâ”€â”€ å‡ ä½•åˆ†ææ¨¡å—
â”‚   â”œâ”€â”€ AABBå‡ ä½•åˆ†æå™¨
â”‚   â”œâ”€â”€ è§‚å¯Ÿç­–ç•¥ç”Ÿæˆå™¨
â”‚   â””â”€â”€ è¦†ç›–ç‡è¯„ä¼°å™¨
â””â”€â”€ ç³»ç»Ÿé›†æˆå±‚
    â”œâ”€â”€ å¢å¼ºå‹RocAgent
    â”œâ”€â”€ é…ç½®ç®¡ç†å™¨
    â””â”€â”€ æ€§èƒ½ç›‘æ§å™¨
```

## è¯¦ç»†å®æ–½æ–¹æ¡ˆ

### æ–¹æ¡ˆ1ï¼šåŒåç‰©ä½“æ™ºèƒ½æ¶ˆæ­§

#### 1.1 æŠ€æœ¯è·¯çº¿

**æ ¸å¿ƒæ€è·¯ï¼š** æ„å»ºå¤šå±‚æ¬¡çš„æ¶ˆæ­§ç³»ç»Ÿï¼Œä»ç®€å•åˆ°å¤æ‚é€çº§å¤„ç†

```
æ¶ˆæ­§æµç¨‹
â”œâ”€â”€ ç¬¬ä¸€å±‚ï¼šå¯å‘å¼è§„åˆ™
â”‚   â”œâ”€â”€ è·ç¦»ä¼˜å…ˆï¼ˆæœ€è¿‘çš„ç‰©ä½“ï¼‰
â”‚   â”œâ”€â”€ å¯è§æ€§ä¼˜å…ˆï¼ˆå¯è§ç‰©ä½“ä¼˜äºä¸å¯è§ï¼‰
â”‚   â””â”€â”€ ç©ºé—´å…³é”®è¯åŒ¹é…ï¼ˆå·¦/å³/å‰/åï¼‰
â”œâ”€â”€ ç¬¬äºŒå±‚ï¼šç©ºé—´å…³ç³»æ¨ç†
â”‚   â”œâ”€â”€ ç›¸å¯¹ä½ç½®è®¡ç®—
â”‚   â”œâ”€â”€ ç¯å¢ƒåœ°æ ‡å‚è€ƒ
â”‚   â””â”€â”€ åŒ…å«å…³ç³»åˆ†æ
â””â”€â”€ ç¬¬ä¸‰å±‚ï¼šVLMé›¶æ ·æœ¬æ¨ç†
    â”œâ”€â”€ ç»“æ„åŒ–æç¤ºç”Ÿæˆ
    â”œâ”€â”€ ç½®ä¿¡åº¦è¯„ä¼°
    â””â”€â”€ äº¤äº’å¼æ¾„æ¸…

```

#### 1.2 å®æ–½æ­¥éª¤

**ç¬¬ä¸€æ­¥ï¼šåŸºç¡€ç©ºé—´å…³ç³»è®¡ç®—**
- åˆ©ç”¨AI2-THORæä¾›çš„ç‰©ä½“å…ƒæ•°æ®ï¼ˆposition, rotation, boundingBoxï¼‰
- è®¡ç®—ç‰©ä½“ç›¸å¯¹äºæ™ºèƒ½ä½“çš„æ–¹ä½ï¼ˆå‰/å/å·¦/å³ï¼‰
- è¯†åˆ«ç¯å¢ƒåœ°æ ‡ï¼ˆçª—æˆ·ã€é—¨ã€å¤§å‹å®¶å…·ï¼‰
- åˆ†æç‰©ä½“é—´çš„åŒ…å«å…³ç³»ï¼ˆæ¡Œä¸Šçš„ä¹¦ã€æ¶å­ä¸Šçš„æ¯å­ï¼‰

**ç¬¬äºŒæ­¥ï¼šè‡ªç„¶è¯­è¨€ç©ºé—´è§£æ**
- æ„å»ºç©ºé—´å…³é”®è¯è¯å…¸ï¼ˆä¸­è‹±æ–‡å¯¹ç…§ï¼‰
  - æ–¹å‘è¯ï¼šleft/å·¦è¾¹, right/å³è¾¹, front/å‰é¢, behind/åé¢
  - è·ç¦»è¯ï¼šnear/é è¿‘, far/è¿œç¦», close to/ç´§é‚»
  - å‚ç…§è¯ï¼šbeside/æ—è¾¹, next to/éš”å£, between/ä¹‹é—´
- ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–ç©ºé—´çº¦æŸ
- å°†è¯­è¨€æè¿°æ˜ å°„åˆ°å‡ ä½•çº¦æŸ

**ç¬¬ä¸‰æ­¥ï¼šå¤šå‡†åˆ™å†³ç­–ç³»ç»Ÿ**
- ç»¼åˆè¯„åˆ†æœºåˆ¶ï¼š
  - ç©ºé—´åŒ¹é…åº¦ï¼ˆ40%ï¼‰- ä¸æŒ‡ä»¤ä¸­ç©ºé—´æè¿°çš„ç¬¦åˆç¨‹åº¦
  - è·ç¦»å› ç´ ï¼ˆ20%ï¼‰- ä¼˜å…ˆé€‰æ‹©è¾ƒè¿‘çš„ç‰©ä½“
  - å¯è§æ€§ï¼ˆ20%ï¼‰- å¯è§ç‰©ä½“ä¼˜äºä¸å¯è§
  - åŒ…å«å…³ç³»ï¼ˆ20%ï¼‰- åŒ¹é…æŒ‡ä»¤ä¸­æåˆ°çš„å®¹å™¨

**ç¬¬å››æ­¥ï¼šæ™ºèƒ½é™çº§ç­–ç•¥**
- é«˜ç½®ä¿¡åº¦ï¼ˆ>0.8ï¼‰ï¼šç›´æ¥æ‰§è¡Œ
- ä¸­ç½®ä¿¡åº¦ï¼ˆ0.5-0.8ï¼‰ï¼šæ‰§è¡Œä½†å‡†å¤‡çº é”™
- ä½ç½®ä¿¡åº¦ï¼ˆ<0.5ï¼‰ï¼šç”Ÿæˆæ¾„æ¸…é—®é¢˜

### æ–¹æ¡ˆ2ï¼šå¤§å‹ç‰©ä½“è‡ªé€‚åº”è§‚å¯Ÿ

#### 2.1 æŠ€æœ¯è·¯çº¿

**æ ¸å¿ƒæ€è·¯ï¼š** åŸºäºç‰©ä½“å‡ ä½•ç‰¹å¾åŠ¨æ€è§„åˆ’è§‚å¯Ÿç­–ç•¥

```
è§‚å¯Ÿç­–ç•¥å†³ç­–æ ‘
â”œâ”€â”€ å‡ ä½•ç‰¹å¾åˆ†æ
â”‚   â”œâ”€â”€ ä½“ç§¯è®¡ç®—ï¼ˆé•¿Ã—å®½Ã—é«˜ï¼‰
â”‚   â”œâ”€â”€ å½¢çŠ¶å› å­ï¼ˆæœ€å¤§ç»´åº¦/æœ€å°ç»´åº¦ï¼‰
â”‚   â””â”€â”€ ç‰©ä½“ç±»å‹ï¼ˆæ²™å‘ã€æ¡Œå­ã€åºŠç­‰ï¼‰
â”œâ”€â”€ ç­–ç•¥ç”Ÿæˆ
â”‚   â”œâ”€â”€ å•è§†è§’è§‚å¯Ÿï¼ˆå°å‹ç®€å•ç‰©ä½“ï¼‰
â”‚   â”œâ”€â”€ å¤šè§†è§’è§‚å¯Ÿï¼ˆå¤§å‹å¤æ‚ç‰©ä½“ï¼‰
â”‚   â””â”€â”€ ç¯ç»•è§‚å¯Ÿï¼ˆç»†é•¿ç‰©ä½“ï¼‰
â””â”€â”€ æ‰§è¡Œä¼˜åŒ–
    â”œâ”€â”€ è·¯å¾„è§„åˆ’ï¼ˆæœ€çŸ­è·¯å¾„ï¼‰
    â”œâ”€â”€ è¦†ç›–ç‡ç›‘æ§
    â””â”€â”€ æå‰ç»ˆæ­¢æ¡ä»¶
```

#### 2.2 å®æ–½æ­¥éª¤

**ç¬¬ä¸€æ­¥ï¼šAABBå‡ ä½•åˆ†æ**
- ä»axisAlignedBoundingBoxæå–å°ºå¯¸ä¿¡æ¯
- è®¡ç®—å…³é”®å‡ ä½•æŒ‡æ ‡ï¼š
  - ä½“ç§¯ = é•¿ Ã— å®½ Ã— é«˜
  - æœ€å¤§ç»´åº¦ = max(é•¿, å®½, é«˜)
  - é•¿å®½æ¯” = æœ€å¤§ç»´åº¦ / æœ€å°ç»´åº¦
  - å½¢çŠ¶åˆ†ç±»ï¼šæ–¹å½¢ã€ç»†é•¿å½¢ã€æ‰å¹³å½¢

**ç¬¬äºŒæ­¥ï¼šè§‚å¯Ÿç­–ç•¥ç”Ÿæˆ**
- å°å‹ç‰©ä½“ï¼ˆä½“ç§¯<0.5mÂ³ï¼‰ï¼šå•ä¸€æ­£é¢è§†è§’
- ä¸­å‹ç‰©ä½“ï¼ˆ0.5-1.0mÂ³ï¼‰ï¼šå‰è§†è§’ + ä¸€ä¸ªä¾§è§†è§’
- å¤§å‹ç‰©ä½“ï¼ˆ>1.0mÂ³ï¼‰ï¼šå¤šè§†è§’è§‚å¯Ÿ
  - Lå‹æ²™å‘ï¼š3-4ä¸ªè§’åº¦è¦†ç›–å„ä¸ªåŒºåŸŸ
  - é•¿æ¡Œï¼šä¸¤ç«¯ + ä¸­é—´è§†è§’
  - é«˜æŸœï¼šåº•éƒ¨ + é¡¶éƒ¨è§†è§’

**ç¬¬ä¸‰æ­¥ï¼šè§†è§’ä¼˜åŒ–ç®—æ³•**
- è®¡ç®—æ¯ä¸ªè§†è§’çš„é¢„æœŸè¦†ç›–ç‡
- ä½¿ç”¨è´ªå¿ƒç®—æ³•é€‰æ‹©ä¿¡æ¯å¢ç›Šæœ€å¤§çš„ä¸‹ä¸€ä¸ªè§†è§’
- å½“ç´¯è®¡è¦†ç›–ç‡è¾¾åˆ°85%æ—¶ç»ˆæ­¢

**ç¬¬å››æ­¥ï¼šè¯­ä¹‰åŒºåŸŸæ˜ å°„**
- å°†å¤§å‹ç‰©ä½“åˆ’åˆ†ä¸ºåŠŸèƒ½åŒºåŸŸï¼š
  - æ²™å‘ï¼šåº§ä½åŒºã€å·¦æ‰¶æ‰‹ã€å³æ‰¶æ‰‹ã€é èƒŒ
  - æ¡Œå­ï¼šä¸­å¿ƒåŒºã€å››è¾¹ç¼˜
  - æŸœå­ï¼šä¸Šå±‚ã€ä¸­å±‚ã€ä¸‹å±‚
- æ”¯æŒç²¾ç¡®çš„åŒºåŸŸå¯¼èˆªï¼ˆ"æŠŠæ¯å­æ”¾åœ¨æ²™å‘å·¦æ‰¶æ‰‹ä¸Š"ï¼‰
## å®æ–½è®¡åˆ’

### ç¬¬ä¸€é˜¶æ®µï¼šæœ€å°å¯è¡Œäº§å“ï¼ˆMVPï¼‰- 2å‘¨

**ç›®æ ‡ï¼š** å®ç°æ ¸å¿ƒåŠŸèƒ½ï¼ŒéªŒè¯æŠ€æœ¯å¯è¡Œæ€§

**Week 1: åŸºç¡€æ¨¡å—å¼€å‘**

- [ ] ç©ºé—´å…³ç³»è®¡ç®—å™¨ï¼ˆç®€åŒ–ç‰ˆï¼‰
  - å®ç°åŸºæœ¬çš„ç›¸å¯¹æ–¹ä½è®¡ç®—
  - æ”¯æŒè·ç¦»å’Œå¯è§æ€§åˆ¤æ–­
- [ ] å¯å‘å¼ç‰©ä½“é€‰æ‹©
  - ç©ºé—´å…³é”®è¯åŒ¹é…
  - åŸºäºè§„åˆ™çš„ç®€å•æ¶ˆæ­§
- [ ] åŠ¨æ€è§‚å¯Ÿè·ç¦»
  - æ›¿æ¢å›ºå®šé˜ˆå€¼
  - åŸºäºç‰©ä½“å¤§å°çš„è·ç¦»è®¡ç®—

**Week 2: ç³»ç»Ÿé›†æˆ**

- [ ] åˆ›å»ºEnhancedRocAgent
  - ç»§æ‰¿åŸæœ‰RocAgent
  - æ·»åŠ å¯é€‰çš„å¢å¼ºåŠŸèƒ½
- [ ] åŸºç¡€æµ‹è¯•æ¡†æ¶
  - è®¾è®¡æµ‹è¯•åœºæ™¯
  - éªŒè¯åŸºæœ¬åŠŸèƒ½

**äº¤ä»˜ç‰©ï¼š**
- å¯è¿è¡Œçš„å¢å¼ºå¯¼èˆªç³»ç»Ÿ
- åŸºç¡€åŠŸèƒ½æµ‹è¯•æŠ¥å‘Š
- æ€§èƒ½å¯¹æ¯”æ•°æ®

### ç¬¬äºŒé˜¶æ®µï¼šåŠŸèƒ½å¢å¼º - 3å‘¨

**ç›®æ ‡ï¼š** å®Œå–„ç³»ç»ŸåŠŸèƒ½ï¼Œæé«˜å‡†ç¡®ç‡å’Œé²æ£’æ€§

**Week 3: é«˜çº§ç©ºé—´æ¨ç†**
- [ ] ç¯å¢ƒåœ°æ ‡è¯†åˆ«
  - æå–åœºæ™¯ä¸­çš„æ ‡å¿—æ€§ç‰©ä½“
  - æ„å»ºç©ºé—´å‚è€ƒç³»
- [ ] è‡ªç„¶è¯­è¨€è§£æå™¨
  - æ”¯æŒä¸­è‹±æ–‡ç©ºé—´æè¿°
  - å¤„ç†å¤åˆç©ºé—´å…³ç³»
- [ ] åŒ…å«å…³ç³»åˆ†æ
  - è¯†åˆ«ç‰©ä½“é—´çš„å®¹å™¨å…³ç³»
  - æ”¯æŒ"æ¡Œä¸Šçš„ä¹¦"ç­‰æè¿°

**Week 4: å¤šè§†è§’è§‚å¯Ÿç³»ç»Ÿ**
- [ ] å‡ ä½•å¤æ‚åº¦è¯„ä¼°
  - åŸºäºAABBçš„å½¢çŠ¶åˆ†æ
  - ç‰©ä½“åˆ†ç±»ï¼ˆç®€å•/å¤æ‚/ç»†é•¿ï¼‰
- [ ] è§†è§’ç”Ÿæˆç®—æ³•
  - æ ¹æ®ç‰©ä½“å½¢çŠ¶ç”Ÿæˆè§‚å¯Ÿç‚¹
  - ä¼˜åŒ–è§†è§’åºåˆ—
- [ ] è¦†ç›–ç‡ç›‘æ§
  - å®æ—¶è®¡ç®—è§‚å¯Ÿè¦†ç›–ç‡
  - æ”¯æŒæå‰ç»ˆæ­¢

**Week 5: æ™ºèƒ½äº¤äº’æœºåˆ¶**
- [ ] ç½®ä¿¡åº¦è¯„ä¼°ç³»ç»Ÿ
  - å¤šç»´åº¦ç½®ä¿¡åº¦è®¡ç®—
  - åŠ¨æ€é˜ˆå€¼è°ƒæ•´
- [ ] æ¾„æ¸…é—®é¢˜ç”Ÿæˆ
  - ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„é—®é¢˜æ¨¡æ¿
  - æœ€å°åŒ–äº¤äº’è½®æ•°
- [ ] é”™è¯¯æ¢å¤æœºåˆ¶
  - å¤±è´¥æ£€æµ‹å’Œå›é€€
  - æ›¿ä»£æ–¹æ¡ˆç”Ÿæˆ

**äº¤ä»˜ç‰©ï¼š**
- å®Œæ•´åŠŸèƒ½çš„å¯¼èˆªç³»ç»Ÿ
- è¯¦ç»†æµ‹è¯•æŠ¥å‘Š
- ç”¨æˆ·äº¤äº’ä¼˜åŒ–æ–¹æ¡ˆ

### ç¬¬ä¸‰é˜¶æ®µï¼šä¼˜åŒ–ä¸éƒ¨ç½² - 2å‘¨

**ç›®æ ‡ï¼š** ç³»ç»Ÿä¼˜åŒ–ï¼Œç”Ÿäº§ç¯å¢ƒéƒ¨ç½²å‡†å¤‡

**Week 6: æ€§èƒ½ä¼˜åŒ–**
- [ ] è®¡ç®—ä¼˜åŒ–
  - ç©ºé—´è®¡ç®—ç»“æœç¼“å­˜
  - å¹¶è¡Œå¤„ç†æ”¯æŒ
  - å†…å­˜ä½¿ç”¨ä¼˜åŒ–
- [ ] å“åº”æ—¶é—´ä¼˜åŒ–
  - å…³é”®è·¯å¾„åˆ†æ
  - ç®—æ³•å¤æ‚åº¦é™ä½
  - é¢„è®¡ç®—ç­–ç•¥

**Week 7: éƒ¨ç½²å‡†å¤‡**
- [ ] é…ç½®ç®¡ç†ç³»ç»Ÿ
  - å‚æ•°å¤–éƒ¨åŒ–
  - è¿è¡Œæ—¶é…ç½®è°ƒæ•´
  - ç‰¹æ€§å¼€å…³
- [ ] ç›‘æ§ä¸æ—¥å¿—
  - æ€§èƒ½æŒ‡æ ‡æ”¶é›†
  - å†³ç­–è¿‡ç¨‹è®°å½•
  - å¼‚å¸¸è¿½è¸ª
- [ ] æ–‡æ¡£å®Œå–„
  - APIæ–‡æ¡£
  - éƒ¨ç½²æŒ‡å—
  - æ•…éšœæ’é™¤æ‰‹å†Œ

**äº¤ä»˜ç‰©ï¼š**
- ç”Ÿäº§å°±ç»ªçš„ç³»ç»Ÿ
- å®Œæ•´æ–‡æ¡£é›†
- éƒ¨ç½²å’Œè¿ç»´æŒ‡å—
## æµ‹è¯•ä¸éªŒè¯ç­–ç•¥

### æµ‹è¯•åœºæ™¯è®¾è®¡

**åœºæ™¯1ï¼šå¤šä¹¦æ¶åœºæ™¯**
- ç¯å¢ƒï¼šå›¾ä¹¦é¦†ï¼ŒåŒ…å«3ä¸ªä¹¦æ¶
- æµ‹è¯•æŒ‡ä»¤ï¼š
  - "å¯¼èˆªåˆ°ä¹¦æ¶" â†’ åº”è¯·æ±‚æ¾„æ¸…
  - "å¯¼èˆªåˆ°å·¦è¾¹çš„ä¹¦æ¶" â†’ åº”é€‰æ‹©æ­£ç¡®ç›®æ ‡
  - "å¯¼èˆªåˆ°çª—æˆ·æ—è¾¹çš„ä¹¦æ¶" â†’ åº”åŸºäºåœ°æ ‡é€‰æ‹©

**åœºæ™¯2ï¼šLå‹æ²™å‘ä»»åŠ¡**
- ç¯å¢ƒï¼šå®¢å…ï¼ŒLå‹å¤§æ²™å‘
- æµ‹è¯•ä»»åŠ¡ï¼š
  - "æŠŠæ•å¤´æ”¾åœ¨æ²™å‘ä¸Š" â†’ åº”è¿›è¡Œå¤šè§†è§’è§‚å¯Ÿ
  - "æŠŠæ•å¤´æ”¾åœ¨æ²™å‘å·¦æ‰¶æ‰‹ä¸Š" â†’ åº”å¯¼èˆªåˆ°ç‰¹å®šåŒºåŸŸ

**åœºæ™¯3ï¼šå¤æ‚å¨æˆ¿åœºæ™¯**
- ç¯å¢ƒï¼šå¨æˆ¿ï¼Œå¤šä¸ªç›¸åŒç±»å‹ç‰©ä½“
- æµ‹è¯•æ¡ˆä¾‹ï¼š
  - 2ä¸ªè‹¹æœåœ¨ä¸åŒä½ç½®
  - 3ä¸ªæ¯å­åœ¨ä¸åŒå®¹å™¨ä¸Š
  - éªŒè¯ç©ºé—´æè¿°ç†è§£èƒ½åŠ›

## æŠ€æœ¯å®ç°è¦ç‚¹

### å…³é”®æŠ€æœ¯æŒ‘æˆ˜ä¸è§£å†³æ–¹æ¡ˆ

**æŒ‘æˆ˜1ï¼šå®æ—¶æ€§è¦æ±‚**
- è§£å†³æ–¹æ¡ˆï¼šé¢„è®¡ç®— + ç¼“å­˜æœºåˆ¶
- ç©ºé—´å…³ç³»ç¼“å­˜æœ‰æ•ˆæœŸï¼š5åˆ†é’Ÿ
- ä½¿ç”¨ç©ºé—´ç´¢å¼•åŠ é€ŸæŸ¥è¯¢

**æŒ‘æˆ˜2ï¼šä¸­æ–‡æ”¯æŒ**
- è§£å†³æ–¹æ¡ˆï¼šåŒè¯­å…³é”®è¯è¯å…¸
- æ”¯æŒå¸¸è§ä¸­æ–‡ç©ºé—´æè¿°
- ç»Ÿä¸€å†…éƒ¨è¡¨ç¤º

**æŒ‘æˆ˜3ï¼šé²æ£’æ€§ä¿è¯**
- è§£å†³æ–¹æ¡ˆï¼šå¤šçº§é™çº§ç­–ç•¥
- ä¿ç•™åŸå§‹åŠŸèƒ½ä½œä¸ºåå¤‡
- å¼‚å¸¸æƒ…å†µè‡ªåŠ¨åˆ‡æ¢

### æ¨¡å—æ¥å£è®¾è®¡

**ç©ºé—´æ„ŸçŸ¥æ¥å£**
```python
class ISpatialPerception:
    def calculate_relations(self, objects: List[Dict]) -> Dict
    def parse_spatial_language(self, instruction: str) -> SpatialConstraints
    def disambiguate(self, candidates: List[Dict], instruction: str) -> DisambiguationResult
```

**å‡ ä½•åˆ†ææ¥å£**
```python
class IGeometricAnalyzer:
    def analyze_geometry(self, obj: Dict) -> GeometryFeatures
    def generate_observation_strategy(self, obj: Dict) -> ObservationStrategy
    def evaluate_coverage(self, observations: List[Dict]) -> CoverageResult
```

## æ€»ç»“

æœ¬æ–¹æ¡ˆé€šè¿‡æ¨¡å—åŒ–ã€æ¸è¿›å¼çš„å®æ–½ç­–ç•¥ï¼Œåœ¨ä¸éœ€è¦é¢å¤–è®­ç»ƒçš„å‰æä¸‹ï¼Œæ˜¾è‘—æå‡Embodied-Reasonerçš„å¯¼èˆªèƒ½åŠ›ã€‚æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š

1. **é›¶è®­ç»ƒæ™ºèƒ½æ¶ˆæ­§** - å……åˆ†åˆ©ç”¨ç°æœ‰æ•°æ®å’Œæ¨¡å‹èƒ½åŠ›
2. **è‡ªé€‚åº”è§‚å¯Ÿç­–ç•¥** - åŸºäºå‡ ä½•åˆ†æçš„åŠ¨æ€å†³ç­–
3. **ä¼˜é›…çš„é™çº§æœºåˆ¶** - ç¡®ä¿ç³»ç»Ÿç¨³å®šæ€§å’Œé²æ£’æ€§

å»ºè®®æŒ‰ç…§ä¸‰é˜¶æ®µè®¡åˆ’é€æ­¥å®æ–½ï¼Œåœ¨æ¯ä¸ªé˜¶æ®µç»“æŸæ—¶è¿›è¡Œè¯„ä¼°å’Œè°ƒæ•´ï¼Œç¡®ä¿é¡¹ç›®æˆåŠŸäº¤ä»˜ã€‚
   ```python
   class GeometricAnalyzer:
       def __init__(self):
           self.large_object_threshold = 1.0  # å¯é…ç½®é˜ˆå€¼
           self.coverage_threshold = 0.85     # 85%è¦†ç›–ç‡ç›®æ ‡
           
       def analyze_observation_requirements(self, obj):
           """åŸºäºAABBå‡ ä½•ç‰¹å¾åˆ†æè§‚å¯Ÿéœ€æ±‚
           
           ä¸éœ€è®­ç»ƒï¼Œçº¯å‡ ä½•è®¡ç®—ï¼š
           1. ç‰©ä½“çš„ä¸‰ç»´å°ºå¯¸åˆ†æ
           2. è¡¨é¢å¤æ‚æ€§è¯„ä¼°
           3. æœ€ä¼˜è§‚å¯Ÿç‚¹æ•°é‡è®¡ç®—
           4. è§‚å¯Ÿè·ç¦»å’Œè§’åº¦ä¼˜åŒ–
           """
           aabb = obj['axisAlignedBoundingBox']
           size = aabb['size']
           
           # è®¡ç®—åŸºç¡€å‡ ä½•ç‰¹å¾
           volume = size['x'] * size['y'] * size['z']
           max_dimension = max(size['x'], size['y'], size['z'])
           aspect_ratio = max_dimension / min(size['x'], size['y'], size['z'])
           
           # åˆ¤æ–­æ˜¯å¦éœ€è¦å¤šè§†è§’è§‚å¯Ÿ
           needs_multiview = (
               volume > self.large_object_threshold or
               max_dimension > 2.0 or
               aspect_ratio > 3.0  # ç»†é•¿ç‰©ä½“
           )
           
           if not needs_multiview:
               return {
                   'strategy': 'single_view',
                   'optimal_distance': self.calculate_optimal_distance(obj),
                   'optimal_angle': self.calculate_optimal_angle(obj)
               }
           
           # è®¡ç®—å¤šè§†è§’è§‚å¯Ÿç­–ç•¥
           return {
               'strategy': 'multi_view',
               'required_viewpoints': self.calculate_required_viewpoints(obj),
               'observation_sequence': self.plan_observation_sequence(obj),
               'expected_coverage': self.estimate_coverage(obj)
           }
           
       def calculate_required_viewpoints(self, obj):
           """åŸºäºå‡ ä½•ç‰¹å¾è®¡ç®—æ‰€éœ€è§‚å¯Ÿç‚¹"""
           aabb = obj['axisAlignedBoundingBox']
           size = aabb['size']
           center = aabb['center']
           
           # åŸºäºç‰©ä½“å½¢çŠ¶è®¡ç®—å…³é”®è§‚å¯Ÿç‚¹
           viewpoints = []
           
           # ä¸»è¦è§†è§’ï¼šå‰ã€åã€å·¦ã€å³
           directions = ['front', 'back', 'left', 'right']
           
           for direction in directions:
               offset = self.calculate_viewpoint_offset(size, direction)
               viewpoint = {
                   'position': self.calculate_viewpoint_position(center, offset),
                   'direction': direction,
                   'distance': self.calculate_optimal_distance_for_size(size),
                   'angle': self.calculate_viewing_angle(direction)
               }
               viewpoints.append(viewpoint)
               
           # å¦‚æœç‰©ä½“å¾ˆé«˜ï¼Œæ·»åŠ ä¸Šè§†è§’
           if size['y'] > 1.5:  # é«˜äº1.5ç±³
               viewpoints.append({
                   'position': self.calculate_elevated_viewpoint(center, size),
                   'direction': 'top',
                   'distance': max(size['x'], size['z']) * 1.2,
                   'angle': -30  # ä¿¨è§†è§’åº¦
               })
               
           return viewpoints
   ```

2. **è§‚å¯Ÿå®Œæ•´æ€§è¯„ä¼°å™¨ (`ObservationCompletenessEvaluator.py`)**
   ```python
   class ObservationCompletenessEvaluator:
       def __init__(self):
           self.coverage_threshold = 0.85
           self.observation_history = []
           
       def evaluate_coverage(self, obj, current_viewpoint, observation_history):
           """å®æ—¶è¯„ä¼°è§‚å¯Ÿå®Œæ•´æ€§
           
           çº¯æ•°å­¦è®¡ç®—ï¼Œä¸éœ€è®­ç»ƒï¼š
           1. è®¡ç®—å·²è§‚å¯Ÿçš„è¡¨é¢ç§¯æ¯”ä¾‹
           2. è¯†åˆ«æœªè§‚å¯Ÿçš„å…³é”®åŒºåŸŸ
           3. é¢„æµ‹ä¸‹ä¸€ä¸ªæœ€ä¼˜è§‚å¯Ÿç‚¹
           """
           aabb = obj['axisAlignedBoundingBox']
           total_surface_area = self.calculate_total_surface_area(aabb)
           
           # è®¡ç®—å·²è§‚å¯Ÿçš„è¡¨é¢ç§¯
           observed_area = 0
           for viewpoint in observation_history:
               visible_area = self.calculate_visible_surface_area(
                   aabb, viewpoint['position'], viewpoint['angle']
               )
               observed_area += visible_area
               
           # è®¡ç®—å½“å‰è§‚å¯Ÿçš„æ–°å¢è¦†ç›–
           current_visible_area = self.calculate_visible_surface_area(
               aabb, current_viewpoint['position'], current_viewpoint['angle']
           )
           
           total_observed = min(observed_area + current_visible_area, total_surface_area)
           coverage_ratio = total_observed / total_surface_area
           
           return {
               'coverage_ratio': coverage_ratio,
               'is_sufficient': coverage_ratio >= self.coverage_threshold,
               'information_gain': current_visible_area / total_surface_area,
               'missing_regions': self.identify_missing_regions(aabb, observation_history)
           }
           
       def calculate_visible_surface_area(self, aabb, viewpoint_pos, viewing_angle):
           """è®¡ç®—ä»ç‰¹å®šè§†è§’å¯è§çš„è¡¨é¢ç§¯"""
           # ç®€åŒ–çš„å‡ ä½•è®¡ç®—
           # åœ¨å®é™…å®ç°ä¸­å¯ä»¥ä½¿ç”¨æ›´ç²¾ç¡®çš„çº¿æ€§ä»£æ•°æ–¹æ³•
           size = aabb['size']
           center = aabb['center']
           
           # è®¡ç®—è§†çº¿æ–¹å‘
           view_direction = self.normalize_vector(
               [center['x'] - viewpoint_pos['x'],
                center['y'] - viewpoint_pos['y'],
                center['z'] - viewpoint_pos['z']]
           )
           
           # æ ¹æ®è§†çº¿æ–¹å‘è®¡ç®—å¯è§é¢
           visible_faces = self.determine_visible_faces(view_direction)
           
           visible_area = 0
           for face in visible_faces:
               face_area = self.calculate_face_area(size, face)
               visibility_factor = self.calculate_visibility_factor(
                   view_direction, face, viewing_angle
               )
               visible_area += face_area * visibility_factor
               
           return visible_area
   ```

3. **è‡ªé€‚åº”è·¯å¾„è§„åˆ’å™¨ (`AdaptivePathPlanner.py`)**
   ```python
   class AdaptivePathPlanner:
       def __init__(self):
           self.obstacle_avoidance_distance = 0.5
           self.navigation_tolerance = 0.1
           
       def plan_optimal_observation_sequence(self, obj, required_viewpoints, current_position):
           """è§„åˆ’æœ€ä¼˜çš„è§‚å¯Ÿåºåˆ—
           
           ç®—æ³•ä¼˜åŒ–ï¼Œä¸éœ€è®­ç»ƒï¼š
           1. è®¡ç®—æœ€çŸ­è·¯å¾„é—®é¢˜ï¼ˆTSPç®€åŒ–ç‰ˆï¼‰
           2. è€ƒè™‘ä¿¡æ¯å¢ç›Šå’Œç§»åŠ¨æˆæœ¬
           3. åŠ¨æ€è°ƒæ•´è§‚å¯Ÿåºåˆ—
           """
           
           # è®¡ç®—æ‰€æœ‰è§‚å¯Ÿç‚¹ä¹‹é—´çš„è·ç¦»çŸ©é˜µ
           distance_matrix = self.calculate_distance_matrix(
               [current_position] + required_viewpoints
           )
           
           # ä½¿ç”¨è´ªå¿ƒç®—æ³•è§£å†³TSPï¼ˆè½»é‡çº§ï¼‰
           optimal_sequence = self.greedy_tsp_solve(
               distance_matrix, start_index=0  # ä»å½“å‰ä½ç½®å¼€å§‹
           )
           
           # åŸºäºä¿¡æ¯å¢ç›Šä¼˜åŒ–åºåˆ—
           optimized_sequence = self.optimize_by_information_gain(
               optimal_sequence, obj
           )
           
           return {
               'viewpoint_sequence': optimized_sequence,
               'total_distance': self.calculate_total_distance(optimized_sequence),
               'estimated_time': self.estimate_observation_time(optimized_sequence),
               'expected_coverage': self.estimate_total_coverage(optimized_sequence, obj)
           }
           
       def greedy_tsp_solve(self, distance_matrix, start_index=0):
           """è´ªå¿ƒç®—æ³•è§£å†³æ—…è¡Œå•†é—®é¢˜ï¼ˆè½»é‡çº§ï¼‰"""
           n = len(distance_matrix)
           visited = [False] * n
           path = [start_index]
           visited[start_index] = True
           current = start_index
           
           for _ in range(n - 1):
               nearest_distance = float('inf')
               nearest_node = -1
               
               for next_node in range(n):
                   if not visited[next_node] and distance_matrix[current][next_node] < nearest_distance:
                       nearest_distance = distance_matrix[current][next_node]
                       nearest_node = next_node
                       
               if nearest_node != -1:
                   path.append(nearest_node)
                   visited[nearest_node] = True
                   current = nearest_node
                   
           return path
   ```

## å®æ–½è®¡åˆ’ï¼šåŸºäºç°æœ‰æ¶æ„çš„æ¸è¿›å¼å¢å¼º

### ç¬¬ä¸€é˜¶æ®µï¼šæ ¸å¿ƒç®—æ³•æ¨¡å—å¼€å‘ï¼ˆç¬¬1-3å‘¨ï¼‰

#### 1.1 é›¶è®­ç»ƒåŒåç‰©ä½“åŒºåˆ†æ¨¡å—ï¼ˆç¬¬1å‘¨ï¼‰
**åŸºäºç°æœ‰ `evaluate/RocAgent.py` ç›´æ¥å¢å¼ºï¼š**

1. **å¢å¼ºç°æœ‰ç‰©ä½“é€‰æ‹©é€»è¾‘**
   ```python
   # ä¿®æ”¹ evaluate/RocAgent.py ä¸­çš„ navigate æ–¹æ³•
   class EnhancedRocAgent(RocAgent):
       def __init__(self, *args, **kwargs):
           super().__init__(*args, **kwargs)
           # æ·»åŠ æ–°çš„è§£å†³æ¨¡å—ï¼ˆé›¶è®­ç»ƒï¼‰
           self.spatial_calculator = SpatialRelationCalculator(self.eventobject)
           self.prompt_engine = SmartPromptEngine()
           self.ambiguity_detector = HeuristicAmbiguityDetector()
           
       def enhanced_navigate(self, itemtype, itemname):
           """å¢å¼ºçš„å¯¼èˆªæ–¹æ³•ï¼Œé›¶è®­ç»ƒè§£å†³åŒåç‰©ä½“æ­§ä¹‰
           
           æ›¿æ¢åŸæœ‰çš„ç®€å•ç´¢å¼•é€»è¾‘ï¼š
           if itemtype in self.target_item_type2obj_id:
               obj_id = self.target_item_type2obj_id[itemtype][0]  # åŸå§‹é—®é¢˜
           """
           # è·å–æ‰€æœ‰å€™é€‰ç‰©ä½“
           if itemtype in self.target_item_type2obj_id:
               candidates = self.target_item_type2obj_id[itemtype]
           else:
               # å¦‚æœæ²¡æœ‰é¢„å®šä¹‰çš„ç›®æ ‡ï¼Œä½¿ç”¨ type2objects æŸ¥æ‰¾
               candidates = [obj['objectId'] for obj in 
                           self.eventobject.get_objects_by_type(itemtype)]
               
           if len(candidates) == 0:
               return False, f"No {itemtype} found in scene"
           elif len(candidates) == 1:
               # å•ä¸€å€™é€‰ï¼Œç›´æ¥ä½¿ç”¨
               return super().navigate(itemtype, itemname)
           else:
               # å¤šä¸ªå€™é€‰ï¼Œä½¿ç”¨æ™ºèƒ½åŒºåˆ†
               return self.resolve_object_ambiguity(candidates, itemname)
               
       def resolve_object_ambiguity(self, candidate_ids, instruction):
           """ä½¿ç”¨é›¶è®­ç»ƒæ–¹æ³•è§£å†³ç‰©ä½“æ­§ä¹‰"""
           
           # 1. è·å–å€™é€‰ç‰©ä½“ä¿¡æ¯
           candidate_objects = [self.eventobject.get_object_by_id(obj_id) 
                              for obj_id in candidate_ids]
           
           # 2. è®¡ç®—ç©ºé—´å…³ç³»
           spatial_relations = self.spatial_calculator.calculate_relative_positions(
               candidate_objects
           )
           
           # 3. æ£€æµ‹æ­§ä¹‰
           has_ambiguity, reason = self.ambiguity_detector.detect_ambiguity(
               instruction, candidate_objects
           )
           
           if not has_ambiguity:
               # æ²¡æœ‰æ­§ä¹‰ï¼Œä½¿ç”¨å¯å‘å¼è§„åˆ™é€‰æ‹©æœ€ä½³åŒ¹é…
               best_match = self.heuristic_object_selection(
                   instruction, candidate_objects, spatial_relations
               )
               return self.navigate_to_object(best_match)
           
           # 4. æœ‰æ­§ä¹‰ï¼Œä½¿ç”¨VLMè¿›è¡Œæ™ºèƒ½é€‰æ‹©
           vlm_result = self.prompt_engine.resolve_object_reference(
               instruction, candidate_objects, spatial_relations
           )
           
           if vlm_result['selected_object_id'] and vlm_result['confidence'] > 0.7:
               return self.navigate_to_object(vlm_result['selected_object_id'])
           else:
               # ä»ç„¶æ— æ³•ç¡®å®šï¼Œç”Ÿæˆæ¾„æ¸…é—®é¢˜
               return self.handle_clarification_needed(vlm_result)
   ```

2. **å¯å‘å¼ç‰©ä½“é€‰æ‹©ç®—æ³•**
   ```python
   def heuristic_object_selection(self, instruction, candidates, spatial_relations):
       """åŸºäºç©ºé—´å…³ç³»çš„å¯å‘å¼é€‰æ‹©ï¼ˆæ— éœ€è®­ç»ƒï¼‰
       
       ç®€å•è€Œæœ‰æ•ˆçš„é€‰æ‹©ç­–ç•¥ï¼š
       1. å¦‚æœæŒ‡ä»¤åŒ…å«ç©ºé—´å…³ç³»è¯ï¼Œä¼˜å…ˆåŒ¹é…
       2. å¦åˆ™é€‰æ‹©è·ç¦»æœ€è¿‘çš„ç‰©ä½“
       3. å¦‚æœè·ç¦»ç›¸è¿‘ï¼Œé€‰æ‹©å¯è§æ€§æœ€å¥½çš„
       """
       
       # æ£€æŸ¥æŒ‡ä»¤ä¸­çš„ç©ºé—´å…³ç³»è¯
       spatial_keywords = {
           'left': ['left', 'å·¦', 'å·¦è¾¹'],
           'right': ['right', 'å³', 'å³è¾¹'],
           'near': ['near', 'close', 'é è¿‘', 'é™„è¿‘'],
           'far': ['far', 'è¿œ', 'è¿œçš„']
       }
       
       instruction_lower = instruction.lower()
       
       for direction, keywords in spatial_keywords.items():
           if any(keyword in instruction_lower for keyword in keywords):
               # æ‰¾åˆ°ç©ºé—´å…³ç³»è¯ï¼ŒæŒ‰ç…§ç›¸åº”æ–¹å‘é€‰æ‹©
               return self.select_by_spatial_relation(candidates, spatial_relations, direction)
       
       # æ²¡æœ‰ç©ºé—´å…³ç³»è¯ï¼Œé€‰æ‹©è·ç¦»æœ€è¿‘çš„
       closest_object = min(candidates, 
                           key=lambda obj: spatial_relations[obj['objectId']]['distance_to_agent'])
       return closest_object['objectId']
   ```

#### 1.2 å‡ ä½•é©±åŠ¨è§‚å¯Ÿç­–ç•¥æ¨¡å—ï¼ˆç¬¬2å‘¨ï¼‰
**æ‰©å±•ç°æœ‰ `evaluate/baseAgent.py` è§‚å¯Ÿé€»è¾‘ï¼š**

1. **æ›¿æ¢å›ºåŒ–é˜ˆå€¼çš„è§‚å¯Ÿç­–ç•¥**
   ```python
   # ä¿®æ”¹ evaluate/baseAgent.py ä¸­çš„ compute_closest_positions æ–¹æ³•
   class EnhancedBaseAgent(BaseAgent):
       def __init__(self, *args, **kwargs):
           super().__init__(*args, **kwargs)
           # æ·»åŠ å‡ ä½•åˆ†æå™¨
           self.geometric_analyzer = GeometricAnalyzer()
           self.completeness_evaluator = ObservationCompletenessEvaluator()
           self.path_planner = AdaptivePathPlanner()
           
       def enhanced_compute_positions(self, target_object):
           """æ›¿æ¢åŸæœ‰çš„å›ºå®šé˜ˆå€¼é€»è¾‘
           
           åŸå§‹é—®é¢˜ä»£ç ï¼š
           if item_volume <= 0.2 and item_surface_area <=0.5:
               positions = closest_positions
           else:
               positions = far_positions
           """
           
           # ä½¿ç”¨å‡ ä½•åˆ†ææ›¿æ¢å›ºå®šé˜ˆå€¼
           analysis_result = self.geometric_analyzer.analyze_observation_requirements(
               target_object
           )
           
           if analysis_result['strategy'] == 'single_view':
               # å°å‹ç‰©ä½“ï¼Œå•ä¸€è§†è§’è¶³å¤Ÿ
               optimal_position = self.calculate_single_optimal_position(
                   target_object, 
                   analysis_result['optimal_distance'],
                   analysis_result['optimal_angle']
               )
               return [optimal_position]
           else:
               # å¤§å‹ç‰©ä½“ï¼Œéœ€è¦å¤šè§†è§’è§‚å¯Ÿ
               return self.plan_multiview_observation(target_object, analysis_result)
               
       def plan_multiview_observation(self, target_object, analysis_result):
           """è§„åˆ’å¤šè§†è§’è§‚å¯Ÿåºåˆ—"""
           
           required_viewpoints = analysis_result['required_viewpoints']
           current_position = self.get_current_position()
           
           # ä½¿ç”¨è·¯å¾„è§„åˆ’å™¨ä¼˜åŒ–è§‚å¯Ÿåºåˆ—
           optimal_sequence = self.path_planner.plan_optimal_observation_sequence(
               target_object, required_viewpoints, current_position
           )
           
           return {
               'strategy': 'multi_view',
               'viewpoint_sequence': optimal_sequence['viewpoint_sequence'],
               'total_distance': optimal_sequence['total_distance'],
               'expected_coverage': optimal_sequence['expected_coverage']
           }
           
       def execute_adaptive_observation(self, target_object):
           """æ‰§è¡Œè‡ªé€‚åº”è§‚å¯Ÿç­–ç•¥"""
           
           observation_plan = self.enhanced_compute_positions(target_object)
           
           if observation_plan['strategy'] == 'single_view':
               # å•ä¸€è§†è§’è§‚å¯Ÿ
               position = observation_plan[0]
               return self.navigate_and_observe(position)
           else:
               # å¤šè§†è§’è§‚å¯Ÿ
               observation_history = []
               total_coverage = 0.0
               
               for viewpoint in observation_plan['viewpoint_sequence']:
                   # å¯¼èˆªåˆ°è§‚å¯Ÿç‚¹
                   nav_success = self.navigate_to_position(viewpoint['position'])
                   if not nav_success:
                       continue
                       
                   # æ‰§è¡Œè§‚å¯Ÿ
                   observation = self.observe_from_viewpoint(viewpoint)
                   observation_history.append(observation)
                   
                   # è¯„ä¼°è§‚å¯Ÿå®Œæ•´æ€§
                   coverage_result = self.completeness_evaluator.evaluate_coverage(
                       target_object, viewpoint, observation_history
                   )
                   
                   total_coverage = coverage_result['coverage_ratio']
                   
                   # å¦‚æœè¦†ç›–ç‡å·²ç»è¶³å¤Ÿï¼Œæå‰ç»ˆæ­¢
                   if coverage_result['is_sufficient']:
                       break
                       
               return {
                   'success': True,
                   'total_coverage': total_coverage,
                   'observation_count': len(observation_history),
                   'efficiency_score': total_coverage / len(observation_history)
               }
   ```

#### 1.3 ç³»ç»Ÿé›†æˆæ¥å£å¼€å‘ï¼ˆç¬¬3å‘¨ï¼‰
**æ— ç¼é›†æˆåˆ°ç°æœ‰ç³»ç»Ÿï¼š**

```python
# åˆ›å»ºé€‚é…å™¨æ¨¡å¼ï¼Œä¿æŒå‘åå…¼å®¹
class LightweightEnhancementAdapter:
    """è½»é‡çº§å¢å¼ºé€‚é…å™¨ï¼Œä¸ç ´åç°æœ‰ç³»ç»Ÿ"""
    
    def __init__(self, original_agent):
        self.original_agent = original_agent
        # æ–°çš„å¢å¼ºæ¨¡å—
        self.enhancement_modules = {
            'spatial_calculator': SpatialRelationCalculator(original_agent.eventobject),
            'prompt_engine': SmartPromptEngine(),
            'ambiguity_detector': HeuristicAmbiguityDetector(),
            'geometric_analyzer': GeometricAnalyzer(),
            'completeness_evaluator': ObservationCompletenessEvaluator(),
            'path_planner': AdaptivePathPlanner()
        }
        self.enhancement_enabled = True  # å¯å…³é—­çš„å¼€å…³
        
    def navigate(self, itemtype, itemname):
        """å¢å¼ºçš„å¯¼èˆªæ–¹æ³•ï¼Œå®Œå…¨å…¼å®¹åŸæœ‰æ¥å£"""
        
        if not self.enhancement_enabled:
            # å¦‚æœç¦ç”¨å¢å¼ºï¼Œç›´æ¥ä½¿ç”¨åŸå§‹æ–¹æ³•
            return self.original_agent.navigate(itemtype, itemname)
        
        try:
            # å°è¯•ä½¿ç”¨å¢å¼ºåŠŸèƒ½
            return self.enhanced_navigate(itemtype, itemname)
        except Exception as e:
            # å¦‚æœå¢å¼ºåŠŸèƒ½å¤±è´¥ï¼Œå›é€€åˆ°åŸå§‹æ–¹æ³•
            print(f"Enhancement failed, falling back to original method: {e}")
            return self.original_agent.navigate(itemtype, itemname)
            
    def enhanced_navigate(self, itemtype, itemname):
        """å¢å¼ºçš„å¯¼èˆªé€»è¾‘"""
        
        # è·å–å€™é€‰ç‰©ä½“
        if itemtype in self.original_agent.target_item_type2obj_id:
            candidates = self.original_agent.target_item_type2obj_id[itemtype]
        else:
            candidates = [obj['objectId'] for obj in 
                         self.original_agent.eventobject.get_objects_by_type(itemtype)]
        
        if len(candidates) <= 1:
            # å•ä¸€æˆ–æ— å€™é€‰ï¼Œä½¿ç”¨åŸå§‹æ–¹æ³•
            return self.original_agent.navigate(itemtype, itemname)
        
        # å¤šä¸ªå€™é€‰ï¼Œä½¿ç”¨å¢å¼ºåŠŸèƒ½
        return self.resolve_ambiguity_and_navigate(candidates, itemname)
        
    def resolve_ambiguity_and_navigate(self, candidate_ids, instruction):
        """è§£å†³æ­§ä¹‰å¹¶å¯¼èˆª"""
        
        # è·å–å€™é€‰ç‰©ä½“ä¿¡æ¯
        candidate_objects = [self.original_agent.eventobject.get_object_by_id(obj_id) 
                            for obj_id in candidate_ids]
        
        # è®¡ç®—ç©ºé—´å…³ç³»
        spatial_relations = self.enhancement_modules['spatial_calculator'].calculate_relative_positions(
            candidate_objects
        )
        
        # æ£€æµ‹æ­§ä¹‰
        has_ambiguity, reason = self.enhancement_modules['ambiguity_detector'].detect_ambiguity(
            instruction, candidate_objects
        )
        
        if not has_ambiguity:
            # æ— æ­§ä¹‰ï¼Œä½¿ç”¨å¯å‘å¼é€‰æ‹©
            selected_id = self.heuristic_select(instruction, candidate_objects, spatial_relations)
        else:
            # æœ‰æ­§ä¹‰ï¼Œä½¿ç”¨VLMè§£å†³
            vlm_result = self.enhancement_modules['prompt_engine'].resolve_object_reference(
                instruction, candidate_objects, spatial_relations
            )
            
            if vlm_result['confidence'] > 0.7:
                selected_id = vlm_result['selected_object_id']
            else:
                # æ— æ³•è§£å†³ï¼Œç”Ÿæˆæ¾„æ¸…é—®é¢˜
                return self.handle_clarification_request(vlm_result)
        
        # å¯¼èˆªåˆ°é€‰å®šçš„ç‰©ä½“
        return self.navigate_to_selected_object(selected_id)
        
    def enable_enhancements(self, enabled=True):
        """å…è®¸ç”¨æˆ·æ§åˆ¶æ˜¯å¦å¯ç”¨å¢å¼ºåŠŸèƒ½"""
        self.enhancement_enabled = enabled
        
    def get_enhancement_status(self):
        """è·å–å¢å¼ºåŠŸèƒ½çŠ¶æ€"""
        return {
            'enabled': self.enhancement_enabled,
            'modules_loaded': list(self.enhancement_modules.keys()),
            'fallback_available': True
        }
```

### ç¬¬äºŒé˜¶æ®µï¼šç®—æ³•æµ‹è¯•ä¸ä¼˜åŒ–ï¼ˆç¬¬4-8å‘¨ï¼‰

#### 2.1 åŒåç‰©ä½“åŒºåˆ†ç®—æ³•æµ‹è¯•ï¼ˆç¬¬4-6å‘¨ï¼‰
**åŸºäºç°æœ‰ `inference/hf_infer.py` é›¶è®­ç»ƒé›†æˆï¼š**

1. **VLMæ¥å£é€‚é…å™¨å¼€å‘**
   ```python
   # æ‰©å±• inference/hf_infer.py æ”¯æŒé›¶è®­ç»ƒæ¨ç†
   class ZeroShotInferenceAdapter:
       def __init__(self, base_inference_server):
           self.base_server = base_inference_server
           self.prompt_templates = self.load_optimized_prompts()
           
       def resolve_object_ambiguity(self, image, instruction, candidate_objects, spatial_context):
           """ä½¿ç”¨ç°æœ‰VLMçš„é›¶è®­ç»ƒèƒ½åŠ›è§£å†³æ­§ä¹‰
           
           æ— éœ€è®­ç»ƒçš„è§£å†³æ–¹æ¡ˆï¼š
           1. å¤ç”¨ç°æœ‰çš„æ¨ç†æœåŠ¡å™¨
           2. ä½¿ç”¨ä¼˜åŒ–çš„promptæ¨¡æ¿
           3. è§£æç»“æ„åŒ–è¾“å‡º
           """
           
           # æ„å»ºæ™ºèƒ½æç¤º
           optimized_prompt = self.build_spatial_reasoning_prompt(
               instruction, candidate_objects, spatial_context
           )
           
           # è°ƒç”¨ç°æœ‰çš„æ¨ç†æ¥å£
           response = self.base_server.inference(
               image=image,
               prompt=optimized_prompt,
               temperature=0.1,  # é™ä½éšæœºæ€§
               max_tokens=500
           )
           
           # è§£æç»“æ„åŒ–å“åº”
           return self.parse_object_selection_response(response)
           
       def build_spatial_reasoning_prompt(self, instruction, candidates, spatial_context):
           """æ„å»ºä¼˜åŒ–çš„ç©ºé—´æ¨ç†æç¤º"""
           
           context_description = self.format_spatial_context(candidates, spatial_context)
           
           prompt = f"""
           ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½æœºå™¨äººåŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯é€‰æ‹©æœ€åˆé€‚çš„ç‰©ä½“ã€‚
           
           åœºæ™¯ä¸­çš„ç‰©ä½“ï¼š
           {context_description}
           
           ç”¨æˆ·æŒ‡ä»¤ï¼š"{instruction}"
           
           è¯·ä»¥JSONæ ¼å¼å›å¤ï¼š
           {{
               "selected_object_id": "æœ€åŒ¹é…çš„ç‰©ä½“ID",
               "confidence": ç½®ä¿¡åº¦(0-1),
               "reasoning": "é€‰æ‹©ç†ç”±",
               "ambiguity_detected": æ˜¯å¦æ£€æµ‹åˆ°æ­§ä¹‰,
               "clarification_question": "å¦‚æœæœ‰æ­§ä¹‰ï¼Œæå‡ºçš„æ¾„æ¸…é—®é¢˜"
           }}
           """
           
           return prompt
   ```

2. **ç®—æ³•æ€§èƒ½åŸºå‡†æµ‹è¯•**
   ```python
   # åˆ›å»ºæ€§èƒ½æµ‹è¯•å¥—ä»¶
   class AlgorithmBenchmarkSuite:
       def __init__(self):
           self.test_scenarios = self.load_test_scenarios()
           self.baseline_results = {}
           self.enhanced_results = {}
           
       def run_comprehensive_tests(self):
           """è¿è¡Œå…¨é¢çš„ç®—æ³•æ€§èƒ½æµ‹è¯•"""
           
           test_results = {
               'spatial_relation_accuracy': self.test_spatial_relation_understanding(),
               'ambiguity_detection_precision': self.test_ambiguity_detection(),
               'object_selection_accuracy': self.test_object_selection(),
               'response_time_performance': self.test_response_times(),
               'robustness_under_noise': self.test_robustness()
           }
           
           return test_results
           
       def test_spatial_relation_understanding(self):
           """æµ‹è¯•ç©ºé—´å…³ç³»ç†è§£èƒ½åŠ›"""
           
           test_cases = [
               {"instruction": "æ‹¿èµ·å·¦è¾¹çš„ä¹¦", "expected_direction": "left"},
               {"instruction": "å–é è¿‘çª—æˆ·çš„æ¯å­", "expected_landmark": "window"},
               {"instruction": "è·å–å³ä¾§çš„é¥æ§å™¨", "expected_direction": "right"}
           ]
           
           correct_predictions = 0
           total_cases = len(test_cases)
           
           for case in test_cases:
               # ä½¿ç”¨ç©ºé—´å…³ç³»è®¡ç®—å™¨æµ‹è¯•
               predicted_relation = self.spatial_calculator.extract_spatial_relation(
                   case["instruction"]
               )
               
               if self.validate_spatial_prediction(predicted_relation, case):
                   correct_predictions += 1
                   
           return correct_predictions / total_cases
   ```

#### 2.2 å¤šè§†è§’è§‚å¯Ÿç­–ç•¥æµ‹è¯•ï¼ˆç¬¬6-8å‘¨ï¼‰
**åŸºäºç°æœ‰ `evaluate/RocAgent.py` ç®—æ³•éªŒè¯ï¼š**

1. **å‡ ä½•ç®—æ³•éªŒè¯æµ‹è¯•**
   ```python
   # éªŒè¯å‡ ä½•é©±åŠ¨è§‚å¯Ÿç­–ç•¥çš„æ•ˆæœ
   class MultiViewAlgorithmValidator:
       def __init__(self):
           self.geometric_analyzer = GeometricAnalyzer()
           self.path_planner = AdaptivePathPlanner()
           self.completeness_evaluator = ObservationCompletenessEvaluator()
           
       def validate_observation_strategy(self, test_objects):
           """éªŒè¯å¤šè§†è§’è§‚å¯Ÿç­–ç•¥çš„æ•ˆæœ
           
           æµ‹è¯•ç›®æ ‡ï¼š
           1. éªŒè¯AABBåˆ†æçš„å‡†ç¡®æ€§
           2. æµ‹è¯•è·¯å¾„è§„åˆ’çš„æ•ˆç‡
           3. è¯„ä¼°è§‚å¯Ÿå®Œæ•´æ€§ç®—æ³•
           """
           
           validation_results = []
           
           for obj in test_objects:
               # åˆ†æè§‚å¯Ÿéœ€æ±‚
               analysis_result = self.geometric_analyzer.analyze_observation_requirements(obj)
               
               # éªŒè¯åˆ†æç»“æœçš„åˆç†æ€§
               validation = {
                   'object_id': obj['objectId'],
                   'object_type': obj['objectType'],
                   'predicted_strategy': analysis_result['strategy'],
                   'predicted_viewpoints': len(analysis_result.get('required_viewpoints', [])),
                   'expected_coverage': analysis_result.get('expected_coverage', 0)
               }
               
               # æ‰§è¡Œè§‚å¯Ÿç­–ç•¥éªŒè¯
               if analysis_result['strategy'] == 'multi_view':
                   validation.update(self.validate_multiview_strategy(obj, analysis_result))
               else:
                   validation.update(self.validate_singleview_strategy(obj, analysis_result))
                   
               validation_results.append(validation)
               
           return validation_results
           
       def validate_multiview_strategy(self, obj, analysis_result):
           """éªŒè¯å¤šè§†è§’ç­–ç•¥"""
           
           required_viewpoints = analysis_result['required_viewpoints']
           
           # æµ‹è¯•è·¯å¾„è§„åˆ’ç®—æ³•
           current_position = {'x': 0, 'y': 0, 'z': 0}  # æ¨¡æ‹Ÿèµ·å§‹ä½ç½®
           planned_sequence = self.path_planner.plan_optimal_observation_sequence(
               obj, required_viewpoints, current_position
           )
           
           # æ¨¡æ‹Ÿæ‰§è¡Œè§‚å¯Ÿåºåˆ—
           simulated_coverage = 0.0
           observation_history = []
           
           for viewpoint in planned_sequence['viewpoint_sequence']:
               # æ¨¡æ‹Ÿä»è¯¥è§†è§’çš„è§‚å¯Ÿ
               coverage_result = self.completeness_evaluator.evaluate_coverage(
                   obj, viewpoint, observation_history
               )
               
               simulated_coverage = coverage_result['coverage_ratio']
               observation_history.append({
                   'position': viewpoint['position'],
                   'angle': viewpoint.get('angle', 0),
                   'coverage_gain': coverage_result['information_gain']
               })
               
               # å¦‚æœè¾¾åˆ°è¶³å¤Ÿè¦†ç›–ç‡ï¼Œæå‰ç»ˆæ­¢
               if coverage_result['is_sufficient']:
                   break
                   
           return {
               'actual_viewpoints_used': len(observation_history),
               'final_coverage': simulated_coverage,
               'path_efficiency': simulated_coverage / len(observation_history),
               'strategy_success': simulated_coverage >= 0.85
           }
   ```

2. **æ€§èƒ½å¯¹æ¯”æµ‹è¯•æ¡†æ¶**
   ```python
   class PerformanceComparisonFramework:
       def __init__(self):
           self.baseline_agent = self.create_baseline_agent()
           self.enhanced_agent = self.create_enhanced_agent()
           
       def run_comparison_tests(self, test_scenarios):
           """è¿è¡ŒåŸºçº¿ä¸å¢å¼ºç‰ˆæœ¬çš„å¯¹æ¯”æµ‹è¯•"""
           
           baseline_results = []
           enhanced_results = []
           
           for scenario in test_scenarios:
               # æµ‹è¯•åŸºçº¿ç‰ˆæœ¬
               baseline_result = self.test_observation_strategy(
                   self.baseline_agent, scenario
               )
               baseline_results.append(baseline_result)
               
               # æµ‹è¯•å¢å¼ºç‰ˆæœ¬
               enhanced_result = self.test_observation_strategy(
                   self.enhanced_agent, scenario
               )
               enhanced_results.append(enhanced_result)
               
           # è®¡ç®—æ”¹è¿›æŒ‡æ ‡
           improvement_metrics = self.calculate_improvement_metrics(
               baseline_results, enhanced_results
           )
           
           return {
               'baseline_performance': self.aggregate_results(baseline_results),
               'enhanced_performance': self.aggregate_results(enhanced_results),
               'improvement_metrics': improvement_metrics
           }
           
       def test_observation_strategy(self, agent, scenario):
           """æµ‹è¯•ç‰¹å®šæ™ºèƒ½ä½“çš„è§‚å¯Ÿç­–ç•¥"""
           
           start_time = time.time()
           
           # æ‰§è¡Œè§‚å¯Ÿä»»åŠ¡
           if hasattr(agent, 'execute_adaptive_observation'):
               # å¢å¼ºç‰ˆæœ¬
               result = agent.execute_adaptive_observation(scenario['target_object'])
           else:
               # åŸºçº¿ç‰ˆæœ¬
               result = agent.navigate(scenario['object_type'], scenario['object_name'])
               
           end_time = time.time()
           
           return {
               'scenario_id': scenario['id'],
               'execution_time': end_time - start_time,
               'success': result.get('success', False),
               'coverage_achieved': result.get('total_coverage', 0),
               'observation_count': result.get('observation_count', 1),
               'efficiency_score': result.get('efficiency_score', 0)
           }
   ```

### ç¬¬ä¸‰é˜¶æ®µï¼šç®—æ³•é›†æˆä¸ç³»ç»Ÿè¯„ä¼°ï¼ˆç¬¬9-12å‘¨ï¼‰

#### 3.1 è½»é‡çº§ç³»ç»Ÿé›†æˆï¼ˆç¬¬9-10å‘¨ï¼‰
**åŸºäº `evaluate/evaluate.py` æ— ç¼æ‰©å±•ï¼š**

1. **é›¶è®­ç»ƒå¢å¼ºè¯„ä¼°å™¨**
   ```python
   # æ‰©å±• evaluate/evaluate.py æ— éœ€ä¿®æ”¹æ ¸å¿ƒé€»è¾‘
   class LightweightEnhancedEvaluator:
       def __init__(self, base_evaluator):
           self.base_evaluator = base_evaluator
           # è½»é‡çº§å¢å¼ºæ¨¡å—
           self.enhancement_modules = {
               'ambiguity_resolver': ZeroShotAmbiguityResolver(),
               'multiview_analyzer': GeometricMultiViewAnalyzer(),
               'performance_monitor': RealTimePerformanceMonitor()
           }
           
       def evaluate_with_enhancements(self, test_cases):
           """è¿è¡Œå¢å¼ºç‰ˆè¯„ä¼°ï¼Œå®Œå…¨å…¼å®¹ç°æœ‰æ¥å£
           
           å¢å¼ºç­–ç•¥ï¼š
           1. ä¿æŒåŸæœ‰è¯„ä¼°æµç¨‹ä¸å˜
           2. åœ¨å…³é”®èŠ‚ç‚¹æ’å…¥å¢å¼ºåŠŸèƒ½
           3. è®°å½•æ€§èƒ½æ”¹è¿›æ•°æ®
           4. æä¾›è¯¦ç»†çš„å¯¹æ¯”åˆ†æ
           """
           
           # è¿è¡ŒåŸºçº¿è¯„ä¼°
           baseline_results = self.base_evaluator.evaluate(test_cases)
           
           # è¿è¡Œå¢å¼ºç‰ˆè¯„ä¼°
           enhanced_results = self.run_enhanced_evaluation(test_cases)
           
           # è®¡ç®—æ”¹è¿›æŒ‡æ ‡
           improvement_analysis = self.analyze_improvements(
               baseline_results, enhanced_results
           )
           
           return {
               'baseline_performance': baseline_results,
               'enhanced_performance': enhanced_results,
               'improvement_analysis': improvement_analysis,
               'detailed_metrics': self.calculate_detailed_metrics(test_cases)
           }
           
       def run_enhanced_evaluation(self, test_cases):
           """è¿è¡Œå¢å¼ºç‰ˆæœ¬çš„è¯„ä¼°"""
           
           enhanced_results = []
           
           for case in test_cases:
               start_time = time.time()
               
               # æ£€æŸ¥æ˜¯å¦éœ€è¦æ­§ä¹‰è§£å†³
               if self.contains_potential_ambiguity(case):
                   result = self.evaluate_ambiguity_resolution(case)
               elif self.requires_multiview_observation(case):
                   result = self.evaluate_multiview_observation(case)
               else:
                   # ä½¿ç”¨åŸå§‹è¯„ä¼°æ–¹æ³•
                   result = self.base_evaluator.evaluate_single_case(case)
                   
               result['enhancement_used'] = True
               result['evaluation_time'] = time.time() - start_time
               enhanced_results.append(result)
               
           return enhanced_results
           
       def evaluate_ambiguity_resolution(self, test_case):
           """è¯„ä¼°æ­§ä¹‰è§£å†³èƒ½åŠ›"""
           
           # ä½¿ç”¨é›¶è®­ç»ƒæ­§ä¹‰è§£å†³å™¨
           resolution_result = self.enhancement_modules['ambiguity_resolver'].resolve(
               test_case['instruction'],
               test_case['candidate_objects'],
               test_case['scene_context']
           )
           
           return {
               'case_id': test_case['id'],
               'ambiguity_detected': resolution_result['ambiguity_detected'],
               'selected_object': resolution_result['selected_object_id'],
               'confidence': resolution_result['confidence'],
               'clarification_needed': resolution_result.get('clarification_question') is not None,
               'resolution_time': resolution_result['processing_time']
           }
   ```

2. **å®æ—¶æ€§èƒ½ç›‘æ§å™¨**
   ```python
   class RealTimePerformanceMonitor:
       def __init__(self):
           self.metrics_history = []
           self.current_session = {
               'start_time': time.time(),
               'cases_processed': 0,
               'enhancements_used': 0,
               'success_improvements': 0
           }
           
       def monitor_evaluation_session(self, test_cases, results):
           """ç›‘æ§è¯„ä¼°ä¼šè¯çš„æ€§èƒ½"""
           
           session_metrics = {
               'total_cases': len(test_cases),
               'enhancement_usage_rate': 0,
               'average_processing_time': 0,
               'improvement_statistics': {},
               'resource_usage': self.get_resource_usage()
           }
           
           enhancement_used_count = 0
           total_processing_time = 0
           improvements = {'accuracy': [], 'efficiency': [], 'coverage': []}
           
           for result in results:
               if result.get('enhancement_used', False):
                   enhancement_used_count += 1
                   
               total_processing_time += result.get('evaluation_time', 0)
               
               # è®°å½•æ”¹è¿›æ•°æ®
               if 'improvement_metrics' in result:
                   for metric, value in result['improvement_metrics'].items():
                       if metric in improvements:
                           improvements[metric].append(value)
           
           session_metrics['enhancement_usage_rate'] = enhancement_used_count / len(test_cases)
           session_metrics['average_processing_time'] = total_processing_time / len(test_cases)
           session_metrics['improvement_statistics'] = {
               metric: {
                   'average': np.mean(values) if values else 0,
                   'std': np.std(values) if values else 0,
                   'max': np.max(values) if values else 0
               }
               for metric, values in improvements.items()
           }
           
           return session_metrics
   ```

2. **æµ‹è¯•åœºæ™¯ç”Ÿæˆ**
   ```python
   def generate_evaluation_scenarios():
       """ç”Ÿæˆå…¨é¢çš„è¯„ä¼°åœºæ™¯
       
       åŸºäºç°æœ‰çš„ taskgenerate/ åœºæ™¯ï¼š
       1. æ‰©å±•ç°æœ‰åœºæ™¯åŒ…å«æ­§ä¹‰æƒ…å†µ
       2. æ·»åŠ å¤§å‹ç‰©ä½“ä¸“é—¨æµ‹è¯•åœºæ™¯
       3. åˆ›å»ºæ··åˆæŒ‘æˆ˜åœºæ™¯
       """
       scenarios = {
           "ambiguity_test_cases": [
               {
                   "scene": "FloorPlan1",
                   "objects": [
                       {"type": "Book", "id": "Book_1", "position": "near_window"},
                       {"type": "Book", "id": "Book_2", "position": "on_table"},
                       {"type": "Book", "id": "Book_3", "position": "near_door"}
                   ],
                   "test_instructions": [
                       {"text": "æ‹¿èµ·ä¹¦", "expected": "ambiguity_detected"},
                       {"text": "æ‹¿èµ·çª—æˆ·æ—è¾¹çš„ä¹¦", "expected": "Book_1"},
                       {"text": "æ‹¿èµ·æ¡Œä¸Šçš„ä¹¦", "expected": "Book_2"}
                   ]
               }
           ],
           "large_object_test_cases": [
               {
                   "scene": "FloorPlan201",
                   "target_object": {"type": "Sofa", "shape": "L_shaped"},
                   "task": "æŠŠæ¯å­æ”¾åœ¨æ²™å‘å³ä¾§æ‰¶æ‰‹ä¸Š",
                   "expected_viewpoints": 3,
                   "completeness_threshold": 0.85
               }
           ]
       }
       return scenarios
   ```

#### 3.2 æ€§èƒ½ä¼˜åŒ–ä¸éƒ¨ç½²ï¼ˆç¬¬11-12å‘¨ï¼‰

1. **æ¨ç†æ•ˆç‡ä¼˜åŒ–**
   ```python
   # ä¼˜åŒ– inference/hf_infer.py çš„æ€§èƒ½
   class OptimizedInferenceServer(EnhancedInferenceServer):
       def __init__(self):
           super().__init__()
           # æ·»åŠ ç¼“å­˜æœºåˆ¶
           self.spatial_relation_cache = SpatialRelationCache()
           self.ambiguity_detection_cache = AmbiguityDetectionCache()
           
       def cached_ambiguity_detection(self, image_features, instruction):
           """ä½¿ç”¨ç¼“å­˜åŠ é€Ÿæ­§ä¹‰æ£€æµ‹
           
           ä¼˜åŒ–ç­–ç•¥ï¼š
           1. ç¼“å­˜å¸¸è§çš„ç©ºé—´å…³ç³»è®¡ç®—ç»“æœ
           2. é¢„è®¡ç®—ç‰©ä½“ç‰¹å¾å‘é‡
           3. æ‰¹å¤„ç†ç›¸ä¼¼æŸ¥è¯¢
           """
           cache_key = self.generate_cache_key(image_features, instruction)
           
           if cache_key in self.ambiguity_detection_cache:
               return self.ambiguity_detection_cache[cache_key]
           
           result = self.ambiguity_detector(image_features, instruction)
           self.ambiguity_detection_cache[cache_key] = result
           
           return result
   ```

2. **å†…å­˜ä½¿ç”¨ä¼˜åŒ–**
   ```python
   # é’ˆå¯¹é•¿åºåˆ—è§‚å¯Ÿå†å²çš„å†…å­˜ä¼˜åŒ–
   class MemoryEfficientObservationHistory:
       def __init__(self, max_history_length=10):
           self.max_length = max_history_length
           self.observation_buffer = deque(maxlen=max_history_length)
           
       def add_observation(self, observation):
           """æ·»åŠ æ–°è§‚å¯Ÿï¼Œè‡ªåŠ¨ç®¡ç†å†…å­˜ä½¿ç”¨"""
           # å‹ç¼©å†å²è§‚å¯Ÿ
           compressed_obs = self.compress_observation(observation)
           self.observation_buffer.append(compressed_obs)
           
       def get_coverage_summary(self):
           """è·å–è§‚å¯Ÿè¦†ç›–ç‡æ‘˜è¦ï¼Œä¸ä¿å­˜è¯¦ç»†å†å²"""
           return self.calculate_aggregate_coverage(self.observation_buffer)
   ```

### ç¬¬å››é˜¶æ®µï¼šç®—æ³•ä¼˜åŒ–ä¸æœ€ç»ˆéƒ¨ç½²ï¼ˆç¬¬13-14å‘¨ï¼‰

#### 4.1 ç®—æ³•æ€§èƒ½è°ƒä¼˜

1. **ç®—æ³•å‚æ•°ä¼˜åŒ–**
   ```python
   # å‚æ•°è°ƒä¼˜æ¡†æ¶
   class AlgorithmParameterOptimizer:
       def __init__(self):
           self.parameter_space = {
               # å‡ ä½•åˆ†æå™¨å‚æ•°
               'geometric_analyzer': {
                   'large_object_threshold': [0.8, 1.0, 1.2, 1.5],
                   'coverage_threshold': [0.80, 0.85, 0.90, 0.95],
                   'aspect_ratio_threshold': [2.0, 2.5, 3.0, 3.5]
               },
               # ç©ºé—´å…³ç³»è®¡ç®—å™¨å‚æ•°
               'spatial_calculator': {
                   'distance_weight': [0.3, 0.4, 0.5, 0.6],
                   'landmark_influence': [0.2, 0.3, 0.4, 0.5],
                   'visibility_weight': [0.2, 0.3, 0.4, 0.5]
               },
               # æ­§ä¹‰æ£€æµ‹å™¨å‚æ•°
               'ambiguity_detector': {
                   'confidence_threshold': [0.6, 0.7, 0.8, 0.9],
                   'spatial_keyword_weight': [0.4, 0.5, 0.6, 0.7]
               }
           }
           
       def optimize_parameters(self, validation_data):
           """ä½¿ç”¨ç½‘æ ¼æœç´¢ä¼˜åŒ–ç®—æ³•å‚æ•°"""
           
           best_performance = 0
           best_params = {}
           
           for params in self.generate_parameter_combinations():
               # ä½¿ç”¨å½“å‰å‚æ•°é…ç½®è¿è¡Œæµ‹è¯•
               performance = self.evaluate_with_parameters(params, validation_data)
               
               if performance['overall_score'] > best_performance:
                   best_performance = performance['overall_score']
                   best_params = params
                   
           return {
               'best_parameters': best_params,
               'best_performance': best_performance,
               'optimization_history': self.optimization_history
           }
   ```

2. **è½»é‡çº§éƒ¨ç½²ä¼˜åŒ–**
   ```python
   # éƒ¨ç½²ä¼˜åŒ–å™¨
   class DeploymentOptimizer:
       def __init__(self):
           self.optimization_strategies = [
               'reduce_memory_footprint',
               'optimize_computational_efficiency', 
               'minimize_inference_latency',
               'enable_graceful_degradation'
           ]
           
       def optimize_for_deployment(self, enhanced_system):
           """ä¸ºéƒ¨ç½²ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½"""
           
           optimizations = {}
           
           # å†…å­˜ä¼˜åŒ–
           optimizations['memory'] = self.optimize_memory_usage(enhanced_system)
           
           # è®¡ç®—ä¼˜åŒ–
           optimizations['computation'] = self.optimize_computation(enhanced_system)
           
           # å»¶è¿Ÿä¼˜åŒ–
           optimizations['latency'] = self.optimize_latency(enhanced_system)
           
           # é²æ£’æ€§ä¼˜åŒ–
           optimizations['robustness'] = self.add_fallback_mechanisms(enhanced_system)
           
           return optimizations
           
       def optimize_memory_usage(self, system):
           """ä¼˜åŒ–å†…å­˜ä½¿ç”¨"""
           return {
               'lazy_loading': 'ä»…åœ¨éœ€è¦æ—¶åŠ è½½å¢å¼ºæ¨¡å—',
               'memory_pooling': 'å¤ç”¨è®¡ç®—ç»“æœç¼“å­˜',
               'garbage_collection': 'åŠæ—¶æ¸…ç†ä¸´æ—¶æ•°æ®',
               'estimated_savings': 'å‡å°‘30-40%å†…å­˜å ç”¨'
           }
   ```

#### 4.2 æœ€ç»ˆç³»ç»Ÿéƒ¨ç½²

1. **ç”Ÿäº§ç¯å¢ƒé€‚é…**
   ```python
   # ç”Ÿäº§ç¯å¢ƒé…ç½®
   class ProductionDeploymentConfig:
       def __init__(self):
           self.deployment_modes = {
               'full_enhancement': {
                   'description': 'å¯ç”¨æ‰€æœ‰å¢å¼ºåŠŸèƒ½',
                   'resource_requirement': 'medium',
                   'performance_gain': 'maximum'
               },
               'selective_enhancement': {
                   'description': 'ä»…åœ¨æ£€æµ‹åˆ°éœ€è¦æ—¶å¯ç”¨å¢å¼º',
                   'resource_requirement': 'low',
                   'performance_gain': 'moderate'
               },
               'fallback_mode': {
                   'description': 'å¢å¼ºåŠŸèƒ½å¤±è´¥æ—¶çš„é™çº§æ¨¡å¼',
                   'resource_requirement': 'minimal',
                   'performance_gain': 'baseline'
               }
           }
           
       def configure_deployment(self, environment_constraints):
           """æ ¹æ®ç¯å¢ƒçº¦æŸé…ç½®éƒ¨ç½²"""
           
           if environment_constraints['memory_limit'] < 4:  # GB
               return self.deployment_modes['selective_enhancement']
           elif environment_constraints['cpu_cores'] < 4:
               return self.deployment_modes['selective_enhancement']
           else:
               return self.deployment_modes['full_enhancement']
   ```

## é£é™©è¯„ä¼°ä¸ç¼“è§£ç­–ç•¥

### é«˜é£é™©é¡¹ç›®
1. **ç®—æ³•æ•ˆæœéªŒè¯é£é™©** ğŸ”´
   - **é—®é¢˜**ï¼šé›¶è®­ç»ƒæ–¹æ³•çš„æ•ˆæœå¯èƒ½ä¸å¦‚é¢„æœŸç¨³å®š
   - **ç¼“è§£**ï¼šå»ºç«‹å…¨é¢çš„æµ‹è¯•å¥—ä»¶ï¼Œå¤šåœºæ™¯éªŒè¯ç®—æ³•é²æ£’æ€§
   - **åº”æ€¥é¢„æ¡ˆ**ï¼šä¿ç•™ç°æœ‰åŠŸèƒ½ä½œä¸ºfallbackï¼Œç¡®ä¿ç³»ç»Ÿç¨³å®šè¿è¡Œ

2. **VLMæ¥å£ä¾èµ–é£é™©** ğŸŸ¡
   - **é—®é¢˜**ï¼šä¾èµ–å¤–éƒ¨VLMæœåŠ¡å¯èƒ½å­˜åœ¨å¯ç”¨æ€§å’Œå»¶è¿Ÿé—®é¢˜
   - **ç¼“è§£**ï¼šå®ç°å¤šVLMåç«¯æ”¯æŒï¼Œè®¾ç½®æœ¬åœ°ç¼“å­˜æœºåˆ¶
   - **åº”æ€¥é¢„æ¡ˆ**ï¼šå¼€å‘çº¯å¯å‘å¼è§„åˆ™ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ

### ä¸­é£é™©é¡¹ç›®
3. **é›†æˆå¤æ‚æ€§é£é™©** ğŸŸ¡
   - **é—®é¢˜**ï¼šä¸ç°æœ‰ç³»ç»Ÿçš„æ¥å£åŒ¹é…å¯èƒ½æ¯”é¢„æœŸå¤æ‚
   - **ç¼“è§£**ï¼šé‡‡ç”¨é€‚é…å™¨æ¨¡å¼ï¼Œä¿æŒå‘åå…¼å®¹
   - **åº”æ€¥é¢„æ¡ˆ**ï¼šæä¾›ç‹¬ç«‹æ¨¡å—ç‰ˆæœ¬ï¼Œé™ä½å¯¹åŸç³»ç»Ÿçš„ä¾èµ–

4. **æ€§èƒ½è¾¾æ ‡é£é™©** ğŸŸ¡
   - **é—®é¢˜**ï¼šç®—æ³•æ€§èƒ½å¯èƒ½éœ€è¦å¤šè½®è°ƒä¼˜æ‰èƒ½è¾¾åˆ°ç›®æ ‡
   - **ç¼“è§£**ï¼šè®¾ç½®åˆ†é˜¶æ®µç›®æ ‡ï¼Œå»ºç«‹æŒç»­æ”¹è¿›æœºåˆ¶
   - **åº”æ€¥é¢„æ¡ˆ**ï¼šé‡æ–°è¯„ä¼°æŒ‡æ ‡åˆç†æ€§ï¼Œè°ƒæ•´é¡¹ç›®èŒƒå›´

---

## ğŸ¯ VLM "vase1" å“åº”å¤„ç†å®ç°è®¡åˆ’

### é—®é¢˜åˆ†æ
å½“å‰çŠ¶æ€ï¼šVLMæ¥æ”¶åˆ°"navigate to vase"æŒ‡ä»¤æ—¶ï¼Œåœ¨å­˜åœ¨å¤šä¸ªvaseçš„åœºæ™¯ä¸‹ï¼Œä¼šæ™ºèƒ½åœ°å›å¤"navigate to vase1"ï¼Œä½†ç³»ç»Ÿä¸çŸ¥é“å¦‚ä½•å¤„ç†è¿™ä¸ªç¼–å·å“åº”ã€‚

### è§£å†³æ–¹æ¡ˆï¼šVLMç¼–å·å“åº”è§£æå™¨

#### 1. å¿«é€Ÿä¿®å¤æ–¹æ¡ˆï¼ˆç«‹å³å®æ–½ï¼‰
```python
class VLMResponseParser:
    def __init__(self):
        self.number_pattern = re.compile(r'(\w+)(\d+)')
        
    def parse_numbered_response(self, vlm_response, candidate_objects):
        """è§£æVLMçš„ç¼–å·å“åº”å¦‚'vase1', 'book2'ç­‰"""
        
        # æå–ç‰©ä½“ç±»å‹å’Œç¼–å·
        match = self.number_pattern.search(vlm_response.lower())
        if not match:
            return None
            
        object_type = match.group(1)
        object_number = int(match.group(2))
        
        # ä»å€™é€‰å¯¹è±¡ä¸­æ‰¾åˆ°å¯¹åº”çš„ç‰©ä½“
        same_type_objects = [obj for obj in candidate_objects 
                           if object_type in obj['objectType'].lower()]
        
        if len(same_type_objects) >= object_number:
            # æŒ‰æŸç§ä¸€è‡´çš„é¡ºåºæ’åˆ—å€™é€‰å¯¹è±¡
            sorted_objects = self.sort_objects_consistently(same_type_objects)
            return sorted_objects[object_number - 1]  # 1-based indexing
        
        return None
        
    def sort_objects_consistently(self, objects):
        """æŒ‰ç…§ä¸€è‡´çš„é¡ºåºæ’åˆ—ç‰©ä½“ï¼Œç¡®ä¿ç¼–å·ç¨³å®š"""
        # æŒ‰ä½ç½®æ’åºï¼šä»å·¦åˆ°å³ï¼Œä»å‰åˆ°å
        return sorted(objects, key=lambda obj: (
            obj['position']['x'],  # å·¦å³ä½ç½®
            obj['position']['z']   # å‰åä½ç½®
        ))
```

#### 2. å¢å¼ºçš„æ­§ä¹‰è§£å†³æµç¨‹
```python
class EnhancedAmbiguityResolver:
    def __init__(self):
        self.response_parser = VLMResponseParser()
        
    def resolve_object_reference(self, instruction, candidate_objects, spatial_relations):
        """å¢å¼ºçš„ç‰©ä½“å¼•ç”¨è§£å†³"""
        
        # 1. é¦–å…ˆå°è¯•VLMæ™ºèƒ½é€‰æ‹©
        vlm_response = self.call_vlm_for_disambiguation(
            instruction, candidate_objects, spatial_relations
        )
        
        # 2. æ£€æŸ¥VLMæ˜¯å¦è¿”å›ç¼–å·å“åº”
        if self.contains_numbered_reference(vlm_response):
            selected_object = self.response_parser.parse_numbered_response(
                vlm_response, candidate_objects
            )
            
            if selected_object:
                return {
                    'selected_object_id': selected_object['objectId'],
                    'confidence': 0.8,  # ç¼–å·å“åº”é€šå¸¸æ¯”è¾ƒå¯é 
                    'method': 'vlm_numbered_response',
                    'original_response': vlm_response
                }
        
        # 3. å¦‚æœç¼–å·è§£æå¤±è´¥ï¼Œä½¿ç”¨ç©ºé—´æ¨ç†
        return self.fallback_to_spatial_reasoning(
            instruction, candidate_objects, spatial_relations
        )
        
    def contains_numbered_reference(self, response):
        """æ£€æŸ¥å“åº”ä¸­æ˜¯å¦åŒ…å«ç¼–å·å¼•ç”¨"""
        return bool(re.search(r'\w+\d+', response))
```

#### 3. æ™ºèƒ½æ’åºç­–ç•¥
```python
class SmartObjectSorting:
    def __init__(self):
        self.sorting_strategies = {
            'spatial_left_to_right': self.sort_by_left_to_right,
            'distance_based': self.sort_by_distance,
            'visibility_based': self.sort_by_visibility
        }
        
    def sort_by_left_to_right(self, objects, agent_position):
        """æŒ‰ç…§ä»å·¦åˆ°å³çš„é¡ºåºæ’åˆ—ç‰©ä½“"""
        # è®¡ç®—ç›¸å¯¹äºagentçš„å·¦å³ä½ç½®
        return sorted(objects, key=lambda obj: 
            self.calculate_relative_x_position(obj, agent_position)
        )
        
    def sort_by_distance(self, objects, agent_position):
        """æŒ‰ç…§è·ç¦»æ’åºï¼Œæœ€è¿‘çš„ä¸º1"""
        return sorted(objects, key=lambda obj:
            self.calculate_distance(obj['position'], agent_position)
        )
        
    def get_optimal_sorting_strategy(self, instruction, objects):
        """æ ¹æ®æŒ‡ä»¤é€‰æ‹©æœ€ä¼˜æ’åºç­–ç•¥"""
        if 'left' in instruction.lower() or 'right' in instruction.lower():
            return 'spatial_left_to_right'
        elif 'near' in instruction.lower() or 'close' in instruction.lower():
            return 'distance_based'
        else:
            return 'spatial_left_to_right'  # é»˜è®¤ç­–ç•¥
```

#### 4. é›†æˆåˆ°ç°æœ‰ç³»ç»Ÿ
```python
# åœ¨ spatial_enhancement/enhanced_agent.py ä¸­é›†æˆ
class EnhancedRocAgent:
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.vlm_response_parser = VLMResponseParser()
        self.ambiguity_resolver = EnhancedAmbiguityResolver()
        
    def resolve_object_ambiguity(self, candidate_ids, instruction):
        """å¢å¼ºçš„æ­§ä¹‰è§£å†³ï¼Œæ”¯æŒVLMç¼–å·å“åº”"""
        
        candidate_objects = [self.get_object_by_id(obj_id) 
                           for obj_id in candidate_ids]
        
        # ä½¿ç”¨å¢å¼ºçš„æ­§ä¹‰è§£å†³å™¨
        result = self.ambiguity_resolver.resolve_object_reference(
            instruction, candidate_objects, self.spatial_relations
        )
        
        if result['selected_object_id']:
            return self.navigate_to_object(result['selected_object_id'])
        else:
            return self.handle_unresolved_ambiguity(result)
```

### æµ‹è¯•è®¡åˆ’
1. **å•å…ƒæµ‹è¯•**ï¼šæµ‹è¯•VLMå“åº”è§£æå™¨çš„å„ç§æƒ…å†µ
2. **é›†æˆæµ‹è¯•**ï¼šä½¿ç”¨test_disambiguation.jsonæµ‹è¯•å®Œæ•´æµç¨‹
3. **æ€§èƒ½æµ‹è¯•**ï¼šç¡®ä¿æ–°åŠŸèƒ½ä¸å½±å“ç³»ç»Ÿæ€§èƒ½
4. **è¾¹ç•Œæµ‹è¯•**ï¼šæµ‹è¯•å„ç§è¾¹ç•Œæƒ…å†µå’Œå¼‚å¸¸è¾“å…¥

### æœŸæœ›æ•ˆæœ
- âœ… æ­£ç¡®å¤„ç†"navigate to vase1"ç±»å‹çš„VLMå“åº”
- âœ… åœ¨FloorPlan1åœºæ™¯ä¸­æˆåŠŸåŒºåˆ†å¤šä¸ªvase
- âœ… æä¾›ä¸€è‡´çš„ç‰©ä½“ç¼–å·ç³»ç»Ÿ
- âœ… ä¿æŒå‘åå…¼å®¹æ€§å’Œç³»ç»Ÿç¨³å®šæ€§

### å®æ–½æ—¶é—´è¡¨
- **Phase 1**: å®ç°VLMå“åº”è§£æå™¨ï¼ˆ1å¤©ï¼‰
- **Phase 2**: é›†æˆåˆ°ç°æœ‰ç³»ç»Ÿï¼ˆ1å¤©ï¼‰
- **Phase 3**: æµ‹è¯•å’Œä¼˜åŒ–ï¼ˆ1å¤©ï¼‰

è¿™ä¸ªæ–¹æ¡ˆå°†ç«‹å³è§£å†³å½“å‰çš„"vase1"é—®é¢˜ï¼Œä¸ºæ›´å¤æ‚çš„ç©ºé—´æ¨ç†åŠŸèƒ½å¥ å®šåŸºç¡€ã€‚
