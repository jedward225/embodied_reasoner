# 第二阶段：精细化感知模块设计文档

## 🎯 **阶段目标**
解决**大型物体交互精度不足**问题，实现语义化精确定位，支持"沙发右侧扶手"、"桌子边缘"等精细化指令。

---

## 🏗️ **技术架构设计**

### 核心模块划分

```mermaid
graph TD
    A[用户指令: "把杯子放在沙发右扶手上"] --> B[语义解析器]
    B --> C[空间签名系统 SpatialSignature]
    C --> D[6D位姿估计器]
    C --> E[点云处理器]
    D --> F[精确交互点计算]
    E --> F
    F --> G[BaseAgent增强定位]
    G --> H[AI2THOR精确操作]
    
    I[AI2THOR深度图] --> E
    I --> J[实例分割掩码]
    J --> E
```

### 数据流设计

1. **感知数据获取**
   ```
   AI2THOR Event → 深度图 + 实例分割 → 点云重建 → 物体6D位姿
   ```

2. **空间语义理解**
   ```
   语义指令 → 空间关系解析 → 区域定位 → 精确交互点
   ```

3. **动作执行优化**
   ```
   交互点 → 最优视角计算 → 路径规划 → 精确导航执行
   ```

---

## 📊 **核心数据结构**

### SpatialSignature 类设计

```python
@dataclass
class SpatialSignature:
    """物体的空间签名，包含精细化几何和语义信息"""
    
    # 基础信息
    object_id: str
    object_type: str
    bounding_box: Dict  # AI2THOR原始边界框
    
    # 点云数据
    point_cloud: np.ndarray  # (N, 3) 3D点云
    point_colors: np.ndarray  # (N, 3) RGB颜色
    
    # 6D位姿
    position: np.ndarray  # (3,) 中心位置
    orientation: np.ndarray  # (3, 3) 旋转矩阵
    principal_axes: np.ndarray  # (3, 3) 主成分方向
    
    # 语义区域
    semantic_regions: Dict[str, RegionSignature]
    # 例如: {"left_arm": RegionSignature, "right_arm": RegionSignature}
    
    # 交互能力
    affordances: List[AffordancePoint]
    surface_normals: np.ndarray  # 表面法向量
    
    # 空间关系
    spatial_relations: Dict[str, Any]  # 与其他物体的空间关系
```

### RegionSignature 子区域设计

```python
@dataclass 
class RegionSignature:
    """物体特定区域的空间签名"""
    
    region_name: str  # "left_arm", "right_arm", "back", "seat"
    point_indices: np.ndarray  # 属于该区域的点云索引
    center: np.ndarray  # 区域中心
    normal: np.ndarray  # 区域主法向量
    extent: np.ndarray  # 区域尺寸 (长宽高)
    
    # 交互特性
    accessibility: float  # 可访问性得分 [0,1]
    stability: float     # 放置稳定性得分 [0,1]
    surface_quality: float  # 表面质量得分 [0,1]
```

### AffordancePoint 交互点设计

```python
@dataclass
class AffordancePoint:
    """物体上的可交互点"""
    
    position: np.ndarray  # 3D坐标
    normal: np.ndarray   # 表面法向量
    interaction_type: str  # "pickup", "place", "press", "grasp"
    confidence: float    # 置信度 [0,1]
    approach_direction: np.ndarray  # 推荐接近方向
```

---

## 🔧 **算法设计**

### 1. 点云重建算法

```python
class PointCloudReconstructor:
    """从AI2THOR深度图重建点云"""
    
    def reconstruct_pointcloud(self, 
                              depth_image: np.ndarray,
                              rgb_image: np.ndarray, 
                              instance_mask: np.ndarray,
                              camera_intrinsics: Dict) -> np.ndarray:
        """
        输入: 深度图 + RGB图 + 实例分割掩码 + 相机内参
        输出: 彩色点云 (N, 6) [x,y,z,r,g,b]
        """
        pass
```

### 2. 6D位姿估计算法

```python
class PoseEstimator:
    """基于点云的6D位姿估计"""
    
    def estimate_6d_pose(self, point_cloud: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        使用PCA分析物体的主要方向和位置
        返回: (position, rotation_matrix)
        """
        # PCA主成分分析
        pca = PCA(n_components=3)
        pca.fit(point_cloud)
        
        # 计算主轴方向
        principal_axes = pca.components_
        
        # 处理方向一致性
        # ...
        
        return center, rotation_matrix
```

### 3. 语义区域分割算法

```python
class SemanticRegionSegmenter:
    """基于几何特征的语义区域分割"""
    
    def segment_sofa_regions(self, signature: SpatialSignature) -> Dict[str, RegionSignature]:
        """沙发区域分割: 座位、靠背、左扶手、右扶手"""
        
        # 基于主成分方向进行几何分割
        # 1. 识别座位区域(最低+最大平面)
        # 2. 识别靠背区域(垂直面，座位后方)  
        # 3. 识别扶手区域(座位两侧的垂直结构)
        
        regions = {}
        
        # 座位检测算法
        seat_region = self._detect_seat_region(signature)
        regions["seat"] = seat_region
        
        # 扶手检测算法 
        left_arm, right_arm = self._detect_arm_regions(signature, seat_region)
        regions["left_arm"] = left_arm
        regions["right_arm"] = right_arm
        
        # 靠背检测算法
        back_region = self._detect_back_region(signature, seat_region)
        regions["back"] = back_region
        
        return regions
```

### 4. 精确交互点计算

```python
class InteractionPointCalculator:
    """计算最优交互点"""
    
    def calculate_placement_point(self, 
                                 target_region: RegionSignature,
                                 object_to_place: SpatialSignature) -> AffordancePoint:
        """
        计算在目标区域放置物体的最优点
        考虑因素: 稳定性、可达性、碰撞避免
        """
        
        # 稳定性分析
        stability_score = self._analyze_stability(target_region, object_to_place)
        
        # 可达性分析  
        accessibility_score = self._analyze_accessibility(target_region)
        
        # 综合评分选择最优点
        best_point = self._select_optimal_point(target_region, stability_score, accessibility_score)
        
        return AffordancePoint(
            position=best_point,
            normal=target_region.normal,
            interaction_type="place",
            confidence=max(stability_score, accessibility_score)
        )
```

---

## 🎮 **集成方案**

### BaseAgent 增强

```python
class EnhancedBaseAgent(BaseAgent):
    """增强的BaseAgent，支持精细化定位"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.spatial_perception = SpatialPerceptionModule()
        self.semantic_parser = SemanticParser()
    
    def navigate_to_precise_location(self, instruction: str) -> bool:
        """
        精确导航到语义指定位置
        例如: "navigate to the right arm of the sofa"
        """
        
        # 解析语义指令
        target_object, target_region = self.semantic_parser.parse(instruction)
        
        # 获取物体的空间签名
        signature = self.spatial_perception.get_spatial_signature(target_object)
        
        # 计算最优交互点
        interaction_point = signature.semantic_regions[target_region].center
        
        # 使用增强的定位算法导航
        return self._navigate_to_3d_point(interaction_point)
```

### 向后兼容性

```python
# 保持原有API的兼容性
def calculate_best_view_angles(self, item):
    """增强版本，支持精细化定位"""
    
    # 尝试使用精细化感知
    if hasattr(self, 'spatial_perception'):
        signature = self.spatial_perception.get_spatial_signature(item["objectId"])
        if signature:
            return self._calculate_precise_view_angles(signature)
    
    # 回退到原始算法
    return self._original_calculate_best_view_angles(item)
```

---

## 📋 **实现计划**

### 第一周：基础数据结构
- [ ] 实现 `SpatialSignature` 类
- [ ] 实现 `RegionSignature` 类  
- [ ] 实现 `AffordancePoint` 类
- [ ] 编写基础测试用例

### 第二周：点云处理
- [ ] 实现 `PointCloudReconstructor`
- [ ] 实现 `PoseEstimator` (PCA-based)
- [ ] AI2THOR深度图集成测试
- [ ] 相机内参标定

### 第三周：语义分割
- [ ] 实现 `SemanticRegionSegmenter`
- [ ] 沙发区域分割算法
- [ ] 桌子区域分割算法
- [ ] 语义分割准确性验证

### 第四周：集成优化
- [ ] `EnhancedBaseAgent` 实现
- [ ] 精确交互点计算
- [ ] 性能优化与测试
- [ ] 完整功能验证

---

## 🎯 **成功指标**

### 功能指标
- [ ] 支持 5+ 种大型物体的精细化区域识别
- [ ] 精确定位误差 < 10cm  
- [ ] 语义指令解析准确率 > 90%
- [ ] 系统响应时间 < 2秒

### 测试场景
- [ ] "把杯子放在沙发的右扶手上"
- [ ] "把书放在桌子的左边缘"  
- [ ] "打开柜子的上层门"
- [ ] "把物品放在椅子的座位中央"

---

## 🔄 **下一步行动**

现在开始第一周的工作：**基础数据结构实现**。准备好了吗？让我们开始构建 `SpatialSignature` 类！ 